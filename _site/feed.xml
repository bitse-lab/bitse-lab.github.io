<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-08-06T17:55:14-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Yuxia Zhang</title><subtitle>Research Fellow, Mayo Clinic</subtitle><author><name>Yuxia Zhang</name><email>yuxiazh@bit.edu.cn</email></author><entry><title type="html">Notes for Computer Networks</title><link href="http://localhost:4000/posts/2017/07/computer-networks/" rel="alternate" type="text/html" title="Notes for Computer Networks" /><published>2017-07-05T00:00:00-07:00</published><updated>2017-07-05T00:00:00-07:00</updated><id>http://localhost:4000/posts/2017/07/computer-networks</id><content type="html" xml:base="http://localhost:4000/posts/2017/07/computer-networks/"><![CDATA[<h1 id="chapter-1">Chapter 1</h1>

<h1 id="multiplexing">Multiplexing</h1>
<ul>
  <li>FDM: the frequency spectrum is divided into frequency bands for individual signals.
    <ul>
      <li>Wavelength Division Multiplexing is just FDM at very high frequencies</li>
    </ul>
  </li>
  <li>TDM: the users take turns to use the entire bandwidth for a little burst of time.</li>
  <li>CDMA (Code Division Multiple Access)</li>
</ul>

<h1 id="switching">Switching</h1>
<ul>
  <li>circuit switching
    <ul>
      <li>connection-oriented</li>
      <li>a complete path established prior to the call, which lasts for the duration</li>
    </ul>
  </li>
  <li>message switching</li>
  <li>packet switching
    <ul>
      <li>connection-less</li>
      <li>data is divided into packets</li>
      <li>users share network resources (link, router) with store-and-forward approach.</li>
      <li>route chosen on packet-by-packet basis</li>
      <li>statistical multiplexing: resource are allocated and shared on demand.</li>
    </ul>
  </li>
  <li>Virtual circuit:
    <ul>
      <li>All packets associated with a session follow the same path</li>
      <li>Route is chosen at start of session</li>
      <li>Packets are labeled with a VC# designating the route</li>
    </ul>
  </li>
</ul>

<h1 id="four-sources-of-packet-delay">Four sources of packet delay</h1>
<ul>
  <li>processing</li>
  <li>queuing</li>
  <li>transmission delay</li>
  <li>propagation delay</li>
</ul>

<h1 id="the-network-core">The network core</h1>
<ul>
  <li>mesh of interconnected routers</li>
  <li>how is data transferred through net?
    <ul>
      <li>circuit switching</li>
      <li>packet switching</li>
    </ul>
  </li>
</ul>

<h1 id="network-of-networks">Network of Networks</h1>
<ul>
  <li>ISP: Internet Service Provider</li>
  <li>Tier-1 ISP
    <ul>
      <li>can reach every other network on the Internet without purchasing IP transit or paying settlements</li>
      <li>treat each other as equals</li>
      <li>national/international coverage (e.g. ChinaGBN, ChinaNet)</li>
    </ul>
  </li>
  <li>Tier-2 ISP
    <ul>
      <li>smaller (often) regional ISPs, connect to one or more Tier-1 ISPs, possibly other Tier-2 ISPs</li>
    </ul>
  </li>
  <li>Tier-3 ISP
    <ul>
      <li>last hop (“access”) network (closest to end systems)</li>
    </ul>
  </li>
</ul>

<h1 id="chapter-2">Chapter 2</h1>
<h1 id="hybrid-of-client-server-and-p2p">Hybrid of client-server and P2P</h1>
<ul>
  <li>Skype
    <ul>
      <li>voice-over-IP P2P application</li>
      <li>centralized server: finding address of remote party</li>
      <li>client-client connection: direct (not through server)</li>
    </ul>
  </li>
  <li>Instant messaging
    <ul>
      <li>chatting between two users is P2P</li>
      <li>centralized service: client presence detection/location</li>
    </ul>
  </li>
</ul>

<h1 id="what-transport-services-dies-an-app-need">What transport services dies an app need?</h1>
<ul>
  <li>data loss</li>
  <li>delay</li>
  <li>throughput: some apps (e.g., multimedia) require minimum amount of throughput to be “effective”; other apps (“elastic apps”) make use of whatever throughput they get.</li>
  <li>security
<img src="https://lantaoyu.github.io/files/network-figures/transport-service.png" alt="" /></li>
</ul>

<h1 id="tcp-service">TCP service</h1>
<ul>
  <li>connection-oriented</li>
  <li>reliable transport</li>
  <li>flow control: sender won’t overwhelm receiver</li>
  <li>congestion control: throttle sender when network overloaded</li>
  <li>does not provide: timing, minimum throughput guarantees, security</li>
</ul>

<h1 id="identifying-processes">Identifying processes</h1>
<p>process identifier = IP address + port numbers</p>

<h1 id="domain-name-system">Domain Name System</h1>
<ul>
  <li>map between IP addresses and name.
    <ul>
      <li>www.sjtu.edu.cn –&gt; 202.120.2.119</li>
    </ul>
  </li>
  <li><strong>distributed database</strong> implemented in hierarchy of many <strong>name servers</strong>
<img src="https://lantaoyu.github.io/files/network-figures/hierarchical.png" alt="" />
    <ul>
      <li>TLDs (Top-Level Domains)
        <ul>
          <li>22+ generic TLDs</li>
          <li>about 250 country code TLDs</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>application-layer protocol</strong> host, routers, name servers to communicate to resolve names (address/name translation)</li>
  <li>UDP on port 53</li>
  <li>13 root name services worldwide
    <ul>
      <li>Contacted by local name server that can not resolve name
        <ul>
          <li>contacts authoritative name server if name mapping not known</li>
          <li>gets mapping</li>
          <li>returns mapping to local name server</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>When host makes DNS query, query is sent to its local DNS server
    <ul>
      <li>acts as proxy, forwards query into hierarchy</li>
    </ul>
  </li>
</ul>

<h1 id="dns-protocol-messages">DNS protocol, messages</h1>
<ul>
  <li>DNS protocol: query and reply messages, both with same message format</li>
  <li>identification: 16 bit # for query, reply to query uses same #
<img src="https://lantaoyu.github.io/files/network-figures/dns.png" alt="" /></li>
</ul>

<h1 id="dns-servers">DNS servers</h1>
<ul>
  <li>Three classes:
    <ul>
      <li>root DNS servers</li>
      <li>top-level domain DNS servers: These servers are responsible for top-level domains such as com, org, net, edu, and gov, and all of the country top-level domains such as uk, fr, ca, and jp.</li>
      <li>authoritative DNS servers</li>
    </ul>
  </li>
  <li>There is another important type of DNS server called the local DNS server. A local DNS server does not strictly belong to the hierarchy of servers but is nevertheless central to the DNS architecture</li>
</ul>

<h1 id="httphypertext-transfer-protocol">HTTP（HyperText Transfer Protocol）</h1>
<ul>
  <li>Uses TCP
    <ul>
      <li>client initiates TCP connection (creates socket) to server, port 80</li>
      <li>server accepts TCP connection from client</li>
      <li>HTTP messages exchanged between browser (HTTP client) and Web server (HTTP server)</li>
      <li>TCP connection closed</li>
    </ul>
  </li>
  <li>HTTP is “stateless”
    <ul>
      <li>server maintains no information about past client requests</li>
    </ul>
  </li>
  <li>http request message general format
<img src="https://lantaoyu.github.io/files/network-figures/http-request.png" alt="" /></li>
  <li>method types
    <ul>
      <li>HTTP/1.0
        <ul>
          <li>GET</li>
          <li>POST</li>
          <li>HEAD</li>
        </ul>
      </li>
      <li>HTTP/1.1
        <ul>
          <li>GET, POST, HEAD</li>
          <li>PUT</li>
          <li>DELETE</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h1 id="http-response-status-codes">HTTP response status codes</h1>
<ul>
  <li>Every request gets a response consisting of a status line, and possibly additional information.</li>
  <li>The status line contains a three-digit status code telling whether the request was satisfied, and if not, why not.</li>
</ul>

<h1 id="cookies">Cookies</h1>
<ul>
  <li>four components:
    <ul>
      <li>cookie header line of HTTP response message</li>
      <li>cookie header line in HTTP request message</li>
      <li>cookie file kept on user’s host, managed by user’s browser</li>
      <li>back-end database at Web site</li>
    </ul>
  </li>
</ul>

<h1 id="http-performance">HTTP Performance</h1>
<ul>
  <li>Round Trip Time (RTT): time for a small packet to travel from client to server and back</li>
  <li>Page Load Time (PLT):
    <ul>
      <li>One RTT to initiate TCP connection</li>
      <li>one RTT for HTTP request and first few bytes of HTTP response to return</li>
      <li>file transmission time</li>
      <li>total = 2 * RTT + transmission time</li>
    </ul>
  </li>
</ul>

<h1 id="electronic-mail">Electronic Mail</h1>
<ul>
  <li>mail servers
    <ul>
      <li>mailbox: contains incoming messages for users</li>
      <li>message queue: contains outgoing messages to be sent</li>
      <li>SMTP protocol: between mail servers to send emails messages
        <ul>
          <li>duplex TCP connection at port 25</li>
          <li>client: sending mail server</li>
          <li>server: receiving mail server</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>mail access protocol
<img src="https://lantaoyu.github.io/files/network-figures/mail-access.png" alt="" />
    <ul>
      <li>POP:
        <ul>
          <li>download and delete</li>
          <li>stateless across sessions</li>
        </ul>
      </li>
      <li>IMAP:
        <ul>
          <li>keep all messages at server</li>
          <li>keeps user state across sessions</li>
        </ul>
      </li>
      <li>http: gmail etc</li>
    </ul>
  </li>
</ul>

<h1 id="cdn-content-delivery-network">CDN: Content delivery network</h1>
<ul>
  <li>Replicate Web pages on a bunch of servers</li>
  <li>Efficient distribution of popular content</li>
  <li>Faster delivery for clients</li>
</ul>

<h1 id="mime">MIME</h1>
<ul>
  <li>Multipurpose Internet Mail Extensions</li>
  <li>MIME: to continue to use the RFC 822 format, but to add structure to the message body and define encoding rules for non-ASCII messages.</li>
</ul>

<h1 id="p2p">P2P</h1>
<ul>
  <li>Distributed Hash Table
    <ul>
      <li>The distributed index Database has (key, value) pairs;
        <ul>
          <li>key: content keywords</li>
          <li>value: IP address of the hosts with the content</li>
        </ul>
      </li>
      <li>Assign integer identifier to each peer:
        <ul>
          <li>ID(peer) = hash(IP, port)</li>
          <li>each peer only aware of immediate successor clockwise</li>
        </ul>
      </li>
      <li>How to store (key, value) pairs in peers?
        <ul>
          <li>Rule: store (key, value) pair to the peer that has the closestID.</li>
          <li>Convention: closest is the immediate successor of the key.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h1 id="distributed-hash-table">Distributed Hash Table</h1>
<p>both the number of neighbors per peer as well as the number of messages per query is O(log N), where N is the number of peers.
<img src="https://lantaoyu.github.io/files/network-figures/finger-table.png" alt="" /></p>

<h1 id="socket">Socket</h1>
<ul>
  <li>Socket is locally identified with a port number</li>
  <li>Client needs to know server IP address and socket port number.</li>
  <li>API:
    <ul>
      <li>BIND: associate a local address (port) with a asocket</li>
      <li>LISTEN: announce willingness to accept connections</li>
    </ul>
  </li>
</ul>

<h1 id="chapter-3">Chapter 3</h1>

<h1 id="tcp-and-udp">TCP and UDP</h1>
<p><img src="https://lantaoyu.github.io/files/network-figures/tcp-udp.png" alt="" /></p>
<ul>
  <li>TCP
    <ul>
      <li>Flow control matches sender to receiver</li>
      <li>Congestion control matches sender to network
        <h1 id="ports">Ports</h1>
      </li>
    </ul>
  </li>
  <li>Servers often bind to “well-known ports”</li>
  <li>FTP (20/21), SMTP (25), POP3 (110), IMAP (143), http (80), https(443).</li>
</ul>

<h1 id="connection-oriented-demux-threaded-web-server">Connection-oriented demux: Threaded Web Server</h1>
<ul>
  <li>TCP socket identified by 4-tuple:<br />
(source IP address, source port number, dest IP address, dest port number)</li>
</ul>

<h1 id="connectionless-demux">Connectionless demux</h1>
<ul>
  <li>UDP socket identified by two-tuple:<br />
(dest IP address, dest port number)</li>
</ul>

<h1 id="why-udp">Why UDP?</h1>
<ul>
  <li>no connection establishment (which can add delay)</li>
  <li>no retransmission (which can add delay)</li>
  <li>simple: no connection state at sender, receiver</li>
  <li>small segment header: 8 bytes</li>
  <li>no flow control and congestion control: UDP can blast away as fast as desired</li>
  <li><strong>Examples</strong>:
    <ul>
      <li>short message interaction apps: DNS, SNMP, PRC</li>
      <li>loss tolerant and delay sensitive: ipPhone, SKYPE</li>
    </ul>
  </li>
</ul>

<h1 id="error-detection-code-edc-and-retransmission">Error detection code (EDC) and retransmission</h1>
<ul>
  <li>Parity checking
    <ul>
      <li>single bit parity</li>
      <li>two dimensional bit parity</li>
    </ul>
  </li>
  <li>Checksum: used in Internet (IP, TCP, UDP), but it is weak</li>
  <li>CRC: cyclic redundancy check
    <ul>
      <li>Cyclic Redundancy Check used in link layer can detect all burst errors less than r+1 bits</li>
      <li>Four International Standards Generator Polynomials
  <img src="https://lantaoyu.github.io/files/network-figures/crc.png" alt="" /></li>
      <li>The power of CRC:
        <ul>
          <li>all single-bit errors will be detected</li>
          <li>All two isolated single-bit errors will be detected</li>
          <li>By making (x + 1) a factor of G(x), all errors consisting of an odd number of inverted bits will be detected</li>
          <li>all burst errors of length &lt;= r will be detected</li>
        </ul>
      </li>
      <li>can be constructed in hardware</li>
      <li>CRCs are widely used on links (Ethernet, ADSL, Cable)</li>
    </ul>
  </li>
</ul>

<h1 id="forwarding-error-correction">Forwarding Error Correction</h1>
<ul>
  <li>Hamming Code
    <ul>
      <li>can only correct one bit error</li>
      <li>used when the error rate is low</li>
    </ul>
  </li>
  <li>Convolutional codes and LDPC heavily used in wireless data link layer</li>
</ul>

<h1 id="detection-vs-correction">Detection vs Correction</h1>
<ul>
  <li>Forward Error Correction:
    <ul>
      <li>when errors are expected</li>
      <li>or when no time for transmission</li>
    </ul>
  </li>
  <li>Error Detection and Retransmission
    <ul>
      <li>more efficient when errors are not expected</li>
      <li>burst errors when they do occur</li>
    </ul>
  </li>
</ul>

<h1 id="reliable-data-transfer">Reliable Data Transfer</h1>
<ul>
  <li>RDT 1.0:
    <ul>
      <li>underlying channel perfectly reliable (no error control)</li>
      <li>receiver has enough buffer and CPU power (no flow control)</li>
    </ul>
  </li>
  <li>RDT 2.0: channel with errors
    <ul>
      <li>underlying channel may flip bits in packet (no lost)</li>
      <li><strong>checksum</strong> to detect bit errors</li>
      <li>receiver feedback: control msgs (ACK, NAK)</li>
      <li>sender retransmits pkt on receipt of NAK</li>
      <li><strong>FLAWS</strong>:
        <ul>
          <li>if ACK/NAK corrupted, sender doesn’t know what happened at receiver</li>
          <li>possible duplicate pkt with retransmission</li>
          <li>Handling duplicates:
            <ul>
              <li>sender retransmits current pkt if ACK/NAK garbled</li>
              <li>sender adds <strong>sequence number</strong> to each pkt</li>
              <li>receiver discards duplicate pkt</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>RDT 2.1： receiver handles garbled ACK/NAKs</li>
  <li>RDT 2.2: a NAK-free protocol
    <ul>
      <li>instead of NAK, receiver sends ACK for last pkt received OK, receiver must explicitlyinclude seq # of pkt being ACKed</li>
      <li>duplicate ACK at sender results in same action as NAK: retransmit current pkt</li>
    </ul>
  </li>
  <li>RDT 3.0: channels with errors and loss
    <ul>
      <li>sender waits “reasonable” amount of time for ACK</li>
      <li>requires countdown timer</li>
      <li>to handle duplicate pkt, receiver must specify seq # of pkt being ACKed</li>
    </ul>
  </li>
</ul>

<h1 id="selective-repeat-vs-go-back-n">Selective Repeat vs Go-Back-N</h1>
<ul>
  <li>Go-back-N: timer for oldest in-flight pkt
    <ul>
      <li>cumulative ACK</li>
      <li>retransmit pkt k and all higher seq# pkts in window when timeout(k)</li>
    </ul>
  </li>
  <li>Selective Repeat
    <ul>
      <li>individual ACK</li>
      <li>sender timer for each unACKed pkt</li>
      <li>sender only resends pkts for which ACK not received</li>
    </ul>
  </li>
</ul>

<h1 id="window-overlay-problem">Window Overlay Problem</h1>
<p><img src="https://lantaoyu.github.io/files/network-figures/window-overlay.png" alt="" /></p>
<ul>
  <li>To avoid overlapping new receiving window with the original window, the maximum window size should satisfy:<br /> 
<strong>sending window + receiving window &lt;= (MAX_SEQ + 1)</strong></li>
</ul>

<h2 id="tcp-overview">TCP overview</h2>
<ul>
  <li>end-to-end: no support for multicasting or broadcasting</li>
  <li>reliable byte stream:
    <ul>
      <li>no “message boundaries”</li>
    </ul>
  </li>
  <li>hybrid of GBN and SR
    <ul>
      <li>pipelined segments</li>
      <li>cumulative and piggyback acks</li>
      <li>single retransmission timer</li>
      <li>retransmissions are triggered by
        <ul>
          <li>timeout events</li>
          <li>3 duplicate acks before timer expires: <strong>fast retransmit</strong></li>
        </ul>
      </li>
      <li>only retransmit one segment</li>
    </ul>
  </li>
  <li>full duplex</li>
  <li>sequence number: byte stream “number” of first byte in segment’s data</li>
  <li>TCP checksum:
    <ul>
      <li>TCP checksum checks the header, the data, and a pseudo header.</li>
      <li>The pseudo-header helps detect mis-delivered packets.</li>
      <li>It also violates the protocol hierarchy since the IP addresses in it belong to the IP layer, not to the TCP layer.</li>
    </ul>
  </li>
</ul>

<h2 id="tcp-timer-management">TCP timer management</h2>
<ul>
  <li>Problem: How do we determine the best timeout value for retransmitting segments in the face of a large standard deviation of round-trip delays?</li>
  <li>Solution: uses <strong>dynamic algorithm</strong> that constantly adjusts the timeout interval, based on continuous measurements of network performance.</li>
</ul>

<h2 id="tcp-flow-control">TCP flow control</h2>
<ul>
  <li>announcing window size:the maximum number of bytes that may be sent and received.</li>
  <li>zero window size: sender stop sending. Two exceptions:
    <ul>
      <li>urgent data</li>
      <li>1-byte request for reannounce the window size.</li>
    </ul>
  </li>
</ul>

<h2 id="tcp-congestion-control">TCP congestion control</h2>
<p>Congestion can be caused by:</p>
<ul>
  <li>data in burst (app and transport layer)</li>
  <li>lack of capacity/bandwidth (physical layer)</li>
  <li>insufficient memory of routers (network layer)</li>
  <li>slow processors of routers (network layer)</li>
</ul>

<h2 id="congestion-prevention-policies-in-open-loop-systems">Congestion Prevention Policies in Open Loop Systems</h2>
<p>To achieve congestion control, select appropriate policies at various levels: data link, network, and transport layer.
<img src="https://lantaoyu.github.io/files/network-figures/congestion-policy.png" alt="" /></p>
<ul>
  <li>strategy:
    <ul>
      <li>predict when congestion is about to happen</li>
      <li>reduce rate early</li>
    </ul>
  </li>
  <li>two approaches:
    <ul>
      <li>host-centric: TCP congestion control</li>
      <li>Router-centric: warning bit, choke packet, load shedding</li>
    </ul>
  </li>
</ul>

<h2 id="tcp-congestion-control-1">TCP congestion control</h2>
<ul>
  <li>Sender uses <strong>packet loss</strong> as the network congestion signal
    <ul>
      <li>TCP assume that lost packets are caused by congestion, not by links.</li>
    </ul>
  </li>
  <li>TCP use a Congestion Window (CongWin)next to the window granted by the receiver. The actual window size is the minimum of the two.</li>
  <li>Algorithm:
    <ul>
      <li>When CongWin is below Threshold, sender in slow-start phase, window grows exponentially.</li>
      <li>When CongWin is above Threshold, sender is in congestion-avoidance phase, window grows linearly.</li>
      <li>When a triple duplicate ACK occurs, Threshold and CongWin set to CongWin/2.</li>
      <li>When timeout occurs, Threshold set to CongWin/2 and CongWin is set to 1 MSS.</li>
    </ul>
  </li>
</ul>

<h2 id="tcp-additive-increase-multiplicative-decrease-aimd">TCP Additive Increase, Multiplicative Decrease (AIMD)</h2>
<ul>
  <li><strong>additive increase</strong>: increase CongWin by 1 MSS every RTT until loss detected</li>
  <li><strong>multiplicative decrease</strong>: cut CongWin in half after loss</li>
</ul>

<h2 id="when-should-the-slow-start-exponential-increase-end">When should the slow start (exponential increase) end?</h2>
<ul>
  <li>If there is a loss event:
    <ul>
      <li>sets the value of congestion window to 1</li>
      <li>sets the “slow start threshold” to cwnd/2</li>
    </ul>
  </li>
  <li>when the value of cwnd equals ssthresh, slow start ends and TCP transitions into congestion avoidance mode.</li>
</ul>

<h2 id="when-should-congestion-avoidances-linear-increase-of-1-mss-per-rtt-end">when should congestion avoidance’s linear increase (of 1 MSS per RTT) end?</h2>
<ul>
  <li>a timeout occurs
    <ul>
      <li>The value of cwnd is set to 1 MSS, and the value of ssthresh is updated to half the value of cwnd</li>
    </ul>
  </li>
  <li>a triple duplicate ACK event
    <ul>
      <li>TCP halves the value of cwnd</li>
      <li>the value of ssthresh to be half the value of cwnd</li>
    </ul>
  </li>
</ul>

<h2 id="tcp-throughput">TCP throughput</h2>
<ul>
  <li>Under assumptions, Because TCP’s throughput (that is, rate) increases linearly between the two extreme values, we have:<br />
average throughput = 0.75 * W / RTT</li>
  <li>the throughput of a TCP connection as a function of the loss rate (L), the round-trip time (RTT), and the maximum segment size (MSS):<br />
<img src="https://lantaoyu.github.io/files/network-figures/tcp-throughput.png" alt="" /></li>
</ul>

<h2 id="tcp-fairness">TCP fairness</h2>
<ul>
  <li>A congestion-control mechanism is said to be fair if the average transmission rate of each connection is approximately R/K; that is, each connection gets an equal share of the link bandwidth.</li>
</ul>

<h1 id="chapter-4">Chapter 4</h1>
<h2 id="network-layer-function">Network Layer Function:</h2>
<ul>
  <li><strong>glue/interconnect</strong> lower-level networks together: allow packets to be sent between any pair of hosts</li>
  <li>network layer provides either host-to-host connectionless service or host-to-host connection service, <strong>but not both.</strong></li>
  <li>connection service =&gt; virtual circuit (VC) networks</li>
  <li>connectionless service =&gt; datagram networks</li>
  <li>network-layer connection service is <strong>implemented in the routers in the network core as well as in the end systems</strong></li>
  <li>Internet is a datagram network.</li>
</ul>

<h2 id="router-functions">Router Functions:</h2>
<ul>
  <li>routing</li>
  <li>forwarding/switching</li>
  <li>congestion control: drop packets, update routing table</li>
</ul>

<h2 id="implementation">Implementation</h2>
<ul>
  <li>Router Forwarding Plane are typically implemented in <strong>hardware</strong>.</li>
  <li>ROuter Control Plane are typically implemented in <strong>software</strong>.</li>
</ul>

<h2 id="virtual-circuit">Virtual Circuit</h2>
<ul>
  <li>VC consists of:
    <ul>
      <li>path from source to destination</li>
      <li>VC numbers, one number for each link along the path</li>
      <li>entries in routers along path</li>
    </ul>
  </li>
  <li>Packet carries VC number rather than destination address as the index of forwarding</li>
  <li>VC number can be changed on each link</li>
  <li>Routers maintain connection state information</li>
</ul>

<h2 id="why-not-keep-the-same-vc-number">Why not keep the same VC number?</h2>
<ul>
  <li>replacing the number from link to link reduces the length of the VC field in the packet header.</li>
  <li><strong>VC setup is considerably simplified</strong> by permitting a different VC number at each link along the path of the VC</li>
</ul>

<h2 id="router-four-parts">Router (four parts)</h2>
<ul>
  <li>input port</li>
  <li>output port</li>
  <li>routing processor</li>
  <li>switching fabric</li>
</ul>

<h2 id="input-port-function">Input port function</h2>
<ul>
  <li>physical layer
    <ul>
      <li>bit-level reception</li>
    </ul>
  </li>
  <li>data link layer
    <ul>
      <li>processing (protocol, decapsulation)</li>
    </ul>
  </li>
  <li>network layer
    <ul>
      <li>lookup, forwarding, queuing</li>
    </ul>
  </li>
</ul>

<h2 id="three-types-of-switching">Three types of switching</h2>
<ul>
  <li>memory: The simplest, earliest routers were traditional computers,
with switching between input and output ports being done under direct control of the CPU (routing processor). An input port with an arriving packet first signaled the routing processor via an interrupt. The packet was then copied from the input port into processor memory. The routing processor then extracted the destination address from the header, looked up the appropriate output port in the forwarding table, and copied the packet to the output port’s buffers.</li>
  <li>bus: If multiple packets arrive to the router at the same time, each at a different input port, all but one must wait since only one packet can cross the bus at a time.</li>
  <li>interconnection network: A crossbar switch is an interconnection network consisting of 2N buses that connect N input ports to N output ports. If two packets from two different input ports are destined to the same output port, then one will have to wait at the input, since only one packet can be sent over any given bus at a time.</li>
</ul>

<h2 id="output-ports">Output ports</h2>
<ul>
  <li>switch fabric -&gt; queuing (buffer management) -&gt; data link processing (protocol, decapsulation) -&gt;line termination</li>
</ul>

<h2 id="input-port-queuing">Input port queuing</h2>
<ul>
  <li>fabric slower than input ports combined -&gt; queuing may occur at input queues</li>
  <li><strong>head-of-the-Line (HOL) blocking</strong>: queued datagram at front of queue prevents others in queue from moving forward</li>
</ul>

<h2 id="output-port-queuing">Output Port Queuing</h2>
<ul>
  <li>buffering when arrival rate via switch exceeds output line speed</li>
</ul>

<h2 id="buffer-design">Buffer design</h2>
<ul>
  <li>how much buffer? rule of thumb
    <ul>
      <li>RTT; round-trip time; C: link capacity; N: number of TCP flows</li>
      <li>average buffer = RTT * C</li>
      <li>recent recommendation: with N flows, buffer equal to $RTT * C / \sqrt{N}$</li>
    </ul>
  </li>
</ul>

<h2 id="internets-network-layer">Internet’s network layer</h2>
<ul>
  <li>IP protocol</li>
  <li>routing component: routing protocols compute the forwarding tables that are used to forward packets through the network</li>
  <li>a facility to report errors in datagrams and respond to requests for certain network-layer information: Internet Control Message Protocol (ICMP)</li>
</ul>

<h2 id="datagram-format">Datagram format</h2>
<p><img src="https://lantaoyu.github.io/files/network-figures/ipv4.png" alt="" /></p>
<ul>
  <li>protocol: This field is used only when an IP datagram reaches its final destination. The value of this field indicates the specific transport-layer protocol to which the data portion of this IP datagram should be passed. A value of 6 indicates that the data portion is passed to TCP, while a value of 17 indicates that the data is passed to UDP.</li>
</ul>

<h2 id="header-length">Header length</h2>
<ul>
  <li>IP header: 20 bytes</li>
  <li>TCP header: 20 bytes</li>
</ul>

<h2 id="mtu">MTU</h2>
<p>The maximum amount of data that a link-layer frame can carry is called the maximum transmission unit (MTU).</p>

<h2 id="ip-fragmentation-and-reassembly">IP fragmentation and reassembly</h2>
<ul>
  <li>Reassembling is done in end systems rather than routers.</li>
  <li>maximum transmission unit (MTU) of link layer puts a hard limit to the size of IP datagram</li>
  <li>the designers of IPv4 decided to put the job of datagram reassembly in the end systems rather than in network routers</li>
  <li><em>identification, flag, fragmentation</em> field in the header</li>
  <li>in order for the destination host to be absolutely sure it has received
the last fragment of the original datagram, the last fragment has a flag bit set to 0,
whereas all the other fragments have this flag bit set to 1.</li>
  <li>At the destination, the payload of the datagram is passed to the transport layer
only after the IP layer has fully reconstructed the original IP datagram. If one or
more of the fragments does not arrive at the destination, the incomplete datagram is
discarded and not passed to the transport layer</li>
  <li>Example:<br />
A datagram of 4,000 bytes (20 bytes of IP header plus 3,980 bytes of IP payload) arrives at a router and must be forwarded to a link with an MTU of 1,500 bytes.
<img src="https://lantaoyu.github.io/files/network-figures/ip-fragments.png" alt="" /></li>
</ul>

<h2 id="ip-header-options">IP header options</h2>
<ul>
  <li>security: specifies how secret the datagram is.</li>
  <li>strict source routing: gives the complete path to be followed</li>
  <li>loose source route: gives a list of routers not to be missed</li>
  <li>record route: makes each router append its IP address</li>
  <li>Timestamp: makes each router append its timestamp and address</li>
</ul>

<h2 id="ip-address">IP address</h2>
<ul>
  <li>32 bit identifier for interface of routers and hosts</li>
  <li>written in dotted decimal</li>
  <li>must be globally unique for globally access</li>
  <li>IP requires each host and router interface to have its own IP address. Thus, an IP address is technically associated with an interface, rather than with the host or router containing that interface.</li>
</ul>

<h2 id="subneting">Subneting</h2>
<ul>
  <li>IP network: all computers addressed with a common identical network id
    <ul>
      <li>an IP network is a broadcasting network</li>
      <li>multiple IP networks are interconnected by routers or 3-layer  switch (VLAN)</li>
    </ul>
  </li>
  <li>Problem with large IP networks:
    <ul>
      <li>different computers are administratively controlled by different entities</li>
      <li>broadcasting storm</li>
    </ul>
  </li>
  <li>
    <p>solution: dividing an IP network into two or more networks is called subnetting</p>
  </li>
  <li>What’s a subnet?
    <ul>
      <li>device interfaces with same subnet part of IP address</li>
      <li>can physically reach each other without intervening routers</li>
    </ul>
  </li>
  <li><strong>subnet mask</strong>: 223.1.1.0/24, indicates that the leftmost 24 bits of the 32-bit quantity define the subnet address.</li>
</ul>

<h2 id="classless-ip-addressing">Classless IP Addressing</h2>
<ul>
  <li>VLSM: variable length subnet mask</li>
  <li>IP address = subnet id + host id</li>
  <li>subnet mask: to indicate the subnet portion which is variable length
    <ul>
      <li>a.b.c.d/x, where x is # bits in subnet portion of address</li>
      <li>1 for subnet id bits, 0 for host id bits (e.g. 255.255.255.0)</li>
    </ul>
  </li>
</ul>

<h2 id="the-internets-address-assignment-strategy-cidr-classless-interdomain-routing">The Internet’s address assignment strategy: CIDR (Classless InterDomain Routing)</h2>
<ul>
  <li>problem: routing table explosion</li>
  <li>assign class C addresses in <strong>contiguous blocks</strong> of 256 addresses so that multiple entries in routing table can be aggregated into one (reduced)</li>
  <li>Contiguous blocks of IP addresses with <strong>common prefix</strong> and <strong>the whole range</strong> of that prefix could be aggregated into one route entry.</li>
  <li>Even if there is <strong>a hole</strong> in the blocks of IP addresses the common prefix could still be aggregated with another <strong>longer prefix for the hole</strong>.</li>
</ul>

<h2 id="ip-broadcast-address">IP broadcast address</h2>
<p>When a host sends a datagram with destination address 255.255.255.255, the message is delivered to all hosts on the same subnet. Routers optionally forward the message into neighboring subnets as well</p>

<h2 id="dhcp-dynamic-host-configuration-protocol">DHCP: Dynamic Host Configuration Protocol</h2>
<ul>
  <li>For obtaining a host address</li>
  <li>Four steps:
    <ul>
      <li><strong>DHCP server discovery</strong>: the DHCP client
creates an IP datagram containing its DHCP discover message along with the
broadcast destination IP address of 255.255.255.255 and a “this host” source IP
address of 0.0.0.0.</li>
      <li><strong>DHCP server offer(s)</strong>: A DHCP server receiving a DHCP discover message
responds to the client with a DHCP offer message that is broadcast to all nodes
on the subnet, again using the IP broadcast address of 255.255.255.255</li>
      <li><strong>DHCP request</strong>: The newly arriving client will choose from among one or more
server offers and respond to its selected offer with a DHCP request message,</li>
      <li><strong>DHCP ACK</strong>: The server responds to the DHCP request message with a DHCP ACK message, confirming the requested parameters.</li>
    </ul>
  </li>
</ul>

<h2 id="nat-network-address-translation">NAT: Network Address Translation</h2>
<ul>
  <li>Motivation: hosts in LANs use private IP address and share one public IP address for internet access
    <ul>
      <li>handle public IP address shortage</li>
      <li>can change address of devices in LAN without notifying outside world</li>
      <li>can change ISPs without changing addresses of devices in LANs</li>
      <li>devices inside not explicitly addressable, visible by outside world (a security plus)</li>
    </ul>
  </li>
  <li>uses 16 bit port field</li>
  <li>The NAT-enabled router does not look like a router to the outside world. Instead
the NAT router behaves to the outside world as a single device with a single IP
address.</li>
  <li>NAT is controversial:
    <ul>
      <li>violates independence layering principles</li>
      <li>violates end-to-end argument
        <ul>
          <li>NAT traversals must be taken into account by app designers</li>
        </ul>
      </li>
      <li>address shortage should instead be addressed by IPv6</li>
    </ul>
  </li>
</ul>

<h2 id="nat-traversal-problem">NAT Traversal Problem</h2>
<ul>
  <li>Solution 1: <strong>statically configure NAT</strong> to forward incoming connection requests at given port to server</li>
  <li>Solution 2: Universal Plug and Play:
With UPnP, an application running in a host can request a NAT mapping between its (private IP address, private port number) and the (public IP address, public port number) for some requested public port number.
In summary, UPnP allows external hosts to initiate communication sessions to NATed hosts, using either TCP or UDP.</li>
  <li>Solution 3: relaying (used in Skype)
    <ul>
      <li>NATed client establishes connection to relay</li>
      <li>External client connects to relay</li>
      <li>relay bridges packets between to connections</li>
    </ul>
  </li>
</ul>

<h2 id="icmp">ICMP</h2>
<ul>
  <li>Internet Control Message Protocol</li>
  <li>ICMP is often considered part of IP but architecturally it lies just above IP, as ICMP messages are carried inside IP datagrams. That is, ICMP messages are carried as IP payload</li>
  <li>Note that ICMP messages are used not only for signaling error conditions.</li>
</ul>

<h2 id="ipv6">IPv6</h2>
<ul>
  <li>initial motivation: 32 bit address space soon to be completely allocated</li>
  <li>additional motivation:
    <ul>
      <li>header format helps speed processing/forwarding</li>
      <li>header changes to facilitate QoS</li>
    </ul>
  </li>
  <li>IPv6 datagram format:
  <img src="https://lantaoyu.github.io/files/network-figures/ipv6.png" alt="" />
    <ul>
      <li>fixed length 40 byte header</li>
      <li>extension header allowed</li>
    </ul>
  </li>
  <li>IPv6 increases the size of the IP address from 32 to 128 bits</li>
  <li>The resulting 40-byte fixed-length header allows faster processing of the IP datagram</li>
</ul>

<h2 id="comparison-of-ipv4-and-ipv6">Comparison of IPv4 and IPv6</h2>
<ul>
  <li>IPv4: 20+ byte headers, 12 + 1 fields</li>
  <li>IPv6: 40 byte headers, 8 fields</li>
</ul>

<h2 id="routing-algorithm-classification">Routing Algorithm classification</h2>
<ul>
  <li>global:
    <ul>
      <li>all routers have complete topology and link cost information</li>
      <li><strong>link state algorithm</strong></li>
    </ul>
  </li>
  <li>local:
    <ul>
      <li>routers knows link costs to neighbours, exchange of info with neighbors</li>
      <li><strong>distance vector algorithm</strong></li>
    </ul>
  </li>
  <li>static:
    <ul>
      <li>routers change slowly over time</li>
    </ul>
  </li>
  <li>dynamic:
    <ul>
      <li>routers change more quickly</li>
      <li>periodic update</li>
      <li>in response to network topology and link costs changes</li>
    </ul>
  </li>
  <li>Internet routing algorithms (such as RIP, OSPF, and
BGP) are load-insensitive, as a link’s cost does not explicitly reflect its current (or
recent past) level of congestion.</li>
</ul>

<h2 id="routing-algorithms">Routing algorithms</h2>
<h2 id="link-state-routing-lsr">Link state routing (LSR):</h2>
<ul>
  <li>Each router learns the entire network topology through exchanging information with all other routers, and then calculate least cost path to the other routers.</li>
  <li>Dijkstra’s algorithm to build the sink tree
    <ul>
      <li>The number of times the loop is executed is equal to the number of nodes in the network.
  <img src="https://lantaoyu.github.io/files/network-figures/LS.png" alt="" /></li>
    </ul>
  </li>
</ul>

<h2 id="distance-vector-routing--bellman-ford">Distance Vector Routing / Bellman-Ford</h2>
<ul>
  <li>Each router maintains a table (i.e Distance Vector) with least cost/distance to every other routers.</li>
</ul>

<h2 id="comparison-between-lsr-and-dvr">Comparison between LSR and DVR</h2>
<ul>
  <li>message complexity:
    <ul>
      <li>LSR: with n nodes, E links, O(nE) messages sent totally, O(n^2) complexity</li>
      <li>DVR: exchange between neighbors only, O(n) totally</li>
    </ul>
  </li>
  <li>computation complexity:
    <ul>
      <li>LSR: O(n^2) each node</li>
      <li>DVR: O(n) each node</li>
    </ul>
  </li>
  <li>speed of convergence:
    <ul>
      <li>LSR: 1 iteration, may have oscilliations</li>
      <li>DVR: n iterations
        <ul>
          <li>good news travel fast</li>
          <li>count-to-infinity problem</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>updating when:
    <ul>
      <li>local link cost change</li>
      <li>LS/DV update message from others/neighbors</li>
      <li>periodically</li>
    </ul>
  </li>
  <li>Neither algorithm is an obvious winner over the other; indeed, both algorithms are used in the Internet.</li>
</ul>

<h2 id="hierarchical-routing">Hierarchical Routing</h2>
<ul>
  <li><strong>Autonomous System (AS)</strong>: aggregate routers into regions, correspond to an administrative domain. Assigned an unique 16/32 bit number</li>
  <li><strong>intra-AS/interior gateway routing</strong> should find the least cost path as best as possible
    <ul>
      <li>routers in same AS run same routing protocol</li>
      <li>routers in different AS can run different intra-AS routing protocol</li>
    </ul>
  </li>
  <li><strong>inter-AS/exterior gateway routing</strong> has to deal with a lot of politics. Routers do not automatically use the routes they find, but have to check manually whether it is allowed.</li>
  <li>Why different intra-AS, inter-AS routing?
    <ul>
      <li>policy:
        <ul>
          <li>inter-AS: admins want to have control over how its traffic routed, and who routes through its net. (untrusted)</li>
          <li>intra-AS: single admin, so no policy decisions needed (trusted)</li>
        </ul>
      </li>
      <li>scale: hierarchical routing saves table size, reduced update traffic</li>
      <li>performance:
        <ul>
          <li>intra-AS: can focus on performance</li>
          <li>inter-AS: policy may dominate performance</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="routing-in-the-internet---hierarchical">Routing in the internet - Hierarchical</h2>
<ul>
  <li>most common intra-AS routing protocols
    <ul>
      <li>RIP: Routing Information Protocol</li>
      <li>OSPF: Open Shortest Path First</li>
      <li>IGRP: Interior Gateway Routining Protocol</li>
    </ul>
  </li>
  <li>most common inter-AS routing protocols
    <ul>
      <li>BGP: Border Gateway Protocol</li>
    </ul>
  </li>
</ul>

<h2 id="rip-routing-information-protocol">RIP (Routing Information Protocol)</h2>
<ul>
  <li>Distance Vector Algorithm</li>
  <li>DV advertisement exchanged among neighbors every 30 sec in UDP packets</li>
  <li>In RIP (and also in OSPF), costs are actually from source router to a <strong>destination
subnet</strong>. RIP uses the term hop, which is <strong>the number of subnets</strong> traversed
along the shortest path from source router to destination subnet, including the destination
subnet.</li>
  <li>distance metric: # of hops, Limits networks to 15 hops (16 = inf to avoid count-to-infinity)</li>
</ul>

<h2 id="ospf-open-shortest-path-protocol">OSPF (Open Shortest Path Protocol)</h2>
<ul>
  <li>“open”: the routing protocol specification is publicly available</li>
  <li>OSPF is a link-state protocol that uses flooding of link-state information and a Dijkstra least-cost path algorithm</li>
  <li>OSPF advertisements disseminated to entireAS</li>
  <li><strong>hierarchical OSPF</strong> in large domains</li>
</ul>

<h2 id="rip-and-ospf">RIP and OSPF</h2>
<ul>
  <li>OSPF and its closely related cousin, IS-IS, are typically deployed in upper-tier ISPs</li>
  <li>RIP is deployed in lower-tier ISPs and enterprise networks</li>
</ul>

<h2 id="hierarchical-ospf">Hierarchical OSPF</h2>
<ul>
  <li>An OSPF autonomous system can be configured hierarchically into areas. Each
area runs its own OSPF link-state routing algorithm, with each router in an area
broadcasting its link state to all other routers in that area.</li>
  <li>two level hierarchy:
    <ul>
      <li>local area: run OSPF</li>
      <li>backbone: area 0</li>
    </ul>
  </li>
  <li>four kinds routers
    <ul>
      <li>internal routers (IR)</li>
      <li>area border routers (ABR): Within each area, one or more area border routers are responsible for routing packets outside the area</li>
      <li>backbone routers (BaR): exactly one OSPF area in the AS is configured to be the backbone area. The primary role of the backbone area is to route traffic between the other areas in the AS</li>
      <li>boundary routers (BoR)</li>
    </ul>
  </li>
</ul>

<h2 id="border-gateway-protocol">Border Gateway Protocol</h2>
<ul>
  <li>advertised prefix includes BGP attributes</li>
  <li>route = prefix + AS-path + Next-hop</li>
  <li>router may learn about multiple routes to some prefix. Router must select one from the routes.</li>
  <li>ordered selection rules (for good instead of best route):<br />
    <ol>
      <li>Local preferences (policy)</li>
      <li>Shortest AS-path</li>
      <li>Closet next hop router</li>
      <li>Additional criteria</li>
    </ol>
  </li>
</ul>

<h2 id="broadcast-and-multicast-routing">Broadcast and multicast routing</h2>
<h2 id="broadcast-routing">broadcast routing:</h2>
<ul>
  <li>deliver packets from source to all other routers</li>
  <li>source duplication is inefficient</li>
  <li>in-network duplication can be more efficient with controlled duplicate transmission</li>
  <li><strong>flooding</strong>: when node receives brdcst pckt, sends copies to all neighbors</li>
  <li><strong>controlled flooding</strong>: node only brdcsts pkt if it hasn’t brdcst same packet before
    <ul>
      <li>node keeps track of pckt IDs already brdcsted</li>
      <li><strong>reverse path forwarding (RPF)</strong>: only forward pckt if it arrived on shortest path between node and source</li>
    </ul>
  </li>
  <li>spanning tree: no redundant packets received by any nodes
    <ul>
      <li>nodes forward copies only along spanning tree</li>
      <li>Pro: makes excellent use of bandwidth</li>
      <li>Con: each router must have knowledge of some spanning tree</li>
    </ul>
  </li>
</ul>

<h2 id="multicast-routing">Multicast Routing</h2>
<ul>
  <li>goal: find a tree (or trees) connecting routers having local mcast group members
    <ul>
      <li><strong>source-based</strong>: different tree from each sender to rcvrs</li>
      <li><strong>shared-tree</strong>: same tree used by all group members</li>
    </ul>
  </li>
  <li>IP multicasting uses <strong>class D</strong> addresses</li>
  <li>Each class D address identifies a group of hosts.</li>
  <li>Groups are managed using <strong>IGMP (Internet Group Management Protocol)</strong>
    <ul>
      <li>operates between a host and its directly attached router</li>
    </ul>
  </li>
  <li>Network-layer multicast in the Internet consists of two complementary components: IGMP and multicast routing protocols.</li>
  <li>Intra-AS Multi-cast Routing Protocols
    <ul>
      <li>Distance-Vector Multicast Routing Protocol (DVMRP) uses an RPF algorithm with pruning</li>
      <li>Protocol-Independent Multicast (PIM) routing protocol
        <ul>
          <li><strong>dense mode</strong> based on pruned RPF</li>
          <li><strong>Sparse mode</strong> based on pruned spanning tree</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Inter-AS Multi-cast Routing Protocols
    <ul>
      <li>extensions to BGP to allow it to carry routing information for other protocols, including multicast information</li>
      <li>MSDP(Multicast Source Discovery Protocol) to connect centers in PIM sparse mode</li>
    </ul>
  </li>
</ul>

<h1 id="chapter-5-the-data-link-layer">Chapter 5 The Data Link Layer</h1>

<h2 id="checksum">Checksum</h2>
<ul>
  <li>In the TCP and UDP protocols, the Internet checksum is computed over all fields (header and data fields included).</li>
  <li>In IP the checksum is computed over the IP header (since the UDP or TCP segment has its own checksum).</li>
</ul>

<h2 id="data-link-layer">Data link layer</h2>
<ul>
  <li>Data link layer is the place in the protocol stack where software meets hardware (firmware)</li>
  <li>implemented in adapter (network interface card NID) in each host and routers</li>
  <li>Data-link layer has responsibility of transferring datagram from one node to <strong>physically adjacent</strong> node over a link (node-to-node job)</li>
  <li>Datagram transferred by <strong>different link protocols</strong> over multiple links from source to destination.</li>
  <li>point-to-point link protocols
    <ul>
      <li>PPP</li>
      <li>HDLC</li>
    </ul>
  </li>
  <li>broadcast link protocols
    <ul>
      <li>Ethernet</li>
      <li>IEEE802.3</li>
    </ul>
  </li>
</ul>

<h2 id="data-link-layer-services">Data Link Layer Services</h2>
<ul>
  <li>framing: encapsulate datagram into frame, adding <strong>header, trailer</strong></li>
  <li>reliable date transfer between adjacent nodes</li>
  <li>link access for shared medium
    <ul>
      <li>Medium/Multiple Access Control (MAC)</li>
      <li>“MAC” addresses: used in frame headers to identify source, destination</li>
    </ul>
  </li>
</ul>

<h2 id="two-point-to-point-data-link-protocols">Two point-to-point Data Link Protocols</h2>
<ul>
  <li>HDLC (High-Level Data Link Control):
    <ul>
      <li><strong>bit-oriented</strong></li>
      <li><strong>supports flow control and error control</strong></li>
    </ul>
  </li>
  <li>PPP (The Point-to-Point Protocol):
    <ul>
      <li>Internet standard (RFC1661 1662 1663), is used in the Internet for a variety of purposes, including router-to-router traffic and home user-to-ISP traffic.</li>
      <li><strong>byte-oriented</strong></li>
      <li>PPP is a variant of HDLC <strong>without flow/error control</strong>, supporting multiple upper layer protocols</li>
      <li>PPP uses <strong>LCP</strong> to manage links and uses <strong>NCP</strong> to negotiate network-layer options</li>
    </ul>
  </li>
</ul>

<h2 id="ideal-mac-protocol">Ideal MAC Protocol</h2>
<ul>
  <li>for broadcast channel of rate R bps:
    <ul>
      <li>efficient: when one node wants to transmit, it can send at rate R.</li>
      <li>fair: when M nodes want to transmit, each can send at average rate R/M</li>
      <li>fully decentralized:
        <ul>
          <li>no special node to coordinate transmissions</li>
          <li>no synchronization of clocks, slots</li>
        </ul>
      </li>
      <li>simple</li>
    </ul>
  </li>
</ul>

<h2 id="three-broad-classes-of-mac-protocols">Three broad classes of MAC protocols</h2>
<ul>
  <li>Channel Partitioning (static)
    <ul>
      <li>divide channel into smaller “pieces” (TDM, FDM, CDM)</li>
      <li>allocate piece to node for <strong>exclusive use</strong></li>
    </ul>
  </li>
  <li>Random Access (dynamic)
    <ul>
      <li>channel not divided, allow collisions</li>
      <li>“recover” from collisions</li>
    </ul>
  </li>
  <li>Taking turns (dynamic)
    <ul>
      <li>nodes take turns</li>
      <li>nodes with more to send can take longer turns</li>
    </ul>
  </li>
</ul>

<h2 id="random-access-mac-protocol">Random Access MAC Protocol</h2>
<ul>
  <li>random access:
    <ul>
      <li>transmit at full channel data rate R When node has packet to send</li>
      <li>no priori coordination among nodes, possible collision</li>
    </ul>
  </li>
  <li>random access MAC protocol specifies:
    <ul>
      <li>how to detect collisions</li>
      <li>how to recover from collisions (e.g., via delayed retransmissions)</li>
    </ul>
  </li>
  <li>Examples :
    <ul>
      <li>ALOHA, slotted ALOHA</li>
      <li>CSMA, CSMA/CD, CSMA/CA</li>
    </ul>
  </li>
</ul>

<h2 id="aloha">ALOHA</h2>
<ul>
  <li>Nodes transmit immediately whenever data is ready in <strong>pure ALOHA</strong>
    <ul>
      <li>collision possible, retry after a random amount of time.</li>
      <li>frame sent at t0 collides with other frames sent in [t0-1,t0+1]</li>
      <li>Maximum efficiency of Pure ALOHA is 0.18</li>
    </ul>
  </li>
  <li>Nodes transmit at the beginning of next slot whenever data is ready in <strong>slotted ALOHA</strong>
    <ul>
      <li>Maximum efficiency of slottedALOHA is 0.36</li>
    </ul>
  </li>
  <li>Problem: a node’s transmission decision is <strong>independent of</strong> other nodes’ activities</li>
</ul>

<h2 id="csma-carrier-sense-multiple-access">CSMA (Carrier Sense Multiple Access)</h2>
<p>listen before transmit:</p>
<ul>
  <li>If channel sensed idle: transmit entire frame
    <ul>
      <li>p-persistent: transmit with probability p, and defer until next slot with probability 1-p.</li>
    </ul>
  </li>
  <li>If channel sensed busy, defer transmission
    <ul>
      <li>1-persistent: keeping sensing and immediately start transmission when idle</li>
      <li>nonpersistent: wait a random period of time before trying again</li>
    </ul>
  </li>
</ul>

<h2 id="link-layer-addressing">Link-Layer Addressing</h2>
<ul>
  <li>Each adapter in LAN has 48 bit, permanent, globally unique MAC address</li>
  <li>MAC addresses are burned in NIC ROM</li>
  <li><strong>ARP (Address Resolution Protocol)</strong> is used to translate IP address into MAC address</li>
</ul>

<h2 id="ethernet-efficiency">Ethernet efficiency</h2>
<ul>
  <li>Ethernet (bus) efficiency is better than ALOHA, but deteriorates as bit-rate and distance raise
<img src="https://lantaoyu.github.io/files/network-figures/ethernet.png" alt="" /></li>
  <li>Ethernet or CSMA/CD is unsuitable for high speed and long distance networks.</li>
</ul>

<h2 id="collision-region-cr-and-broadcast-region-br">Collision Region (CR) and Broadcast Region (BR)</h2>
<ul>
  <li>Use switch to reduce the collision region</li>
  <li>Use router to reduce the broadcasting region and connect with Internet.</li>
</ul>

<h2 id="virtual-lan">Virtual LAN</h2>
<ul>
  <li>Use switch to reduce the broadcasting region with less overhead and more flexibility</li>
  <li>Multiple VLANs over single switch are different broadcast domains</li>
  <li>VLAN can span multiple switches from different physical location</li>
  <li>VLANs isolate broadcast domains, could only connected by routing</li>
</ul>

<h1 id="chapter-6-wireless-and-mobile-networks">Chapter 6 Wireless and Mobile Networks</h1>
<ul>
  <li>The 802.11(<strong>WiFi</strong>) is the wireless version of 802.3 (Ethernet) , but <strong>much different in physical and data link layer</strong>.
    <ul>
      <li>all use CSMA/CA for multiple access</li>
      <li>all have base-station and ad-hoc network versions</li>
    </ul>
  </li>
  <li>802.15: Bluetooth Architecture
    <ul>
      <li>TDD(Time Division Duplexing) : The master in each piconet defines a series of 625 μsec time slots, with the master getting half the slots and the slaves sharing the other half.</li>
    </ul>
  </li>
</ul>]]></content><author><name>Yuxia Zhang</name><email>yuxiazh@bit.edu.cn</email></author><summary type="html"><![CDATA[Chapter 1]]></summary></entry><entry><title type="html">Notes for Linux Kernel</title><link href="http://localhost:4000/posts/2017/06/linux-kernels/" rel="alternate" type="text/html" title="Notes for Linux Kernel" /><published>2017-06-22T00:00:00-07:00</published><updated>2017-06-22T00:00:00-07:00</updated><id>http://localhost:4000/posts/2017/06/linux</id><content type="html" xml:base="http://localhost:4000/posts/2017/06/linux-kernels/"><![CDATA[<h1 id="introduction">Introduction</h1>
<h2 id="features">Features</h2>
<ul>
  <li>Preemptive multitasking</li>
  <li>Virtual memory</li>
  <li>Shared libraries</li>
  <li>Demand loading, dynamic kernel modules</li>
  <li>TCP/IP networking</li>
  <li>Symmetrical Multi-Processing support</li>
  <li>Open source</li>
</ul>

<h2 id="two-modes-in-linux">Two modes in Linux</h2>
<ul>
  <li>User mode: application software(including different libraries)</li>
  <li>Kernel mode: system calls, linux kernel, hardware</li>
</ul>

<h2 id="whats-a-kernel">What’s a kernel</h2>
<ul>
  <li>executive system monitor</li>
  <li>controls and mediates access to hardware</li>
  <li>implements and supports fundamental abstractions (processes, files, devices)</li>
  <li>schedules/allocates system resources (memory, cpu, disk, descriptors)</li>
  <li>security and protection</li>
  <li>respond to user requests for service (system calls)</li>
</ul>

<h2 id="kernel-design-goal">Kernel design goal</h2>
<p>performance, stability, capability, security and protection, portability, extensibility</p>

<h2 id="linux-source-tree-directories">Linux source tree (directories)</h2>
<ul>
  <li>/root : the home directory for the root user</li>
  <li>/home : the user’s home directories along with directories for services (ftp, http…)</li>
  <li>/bin : commands needed during booting up that may be needed by normal users</li>
  <li>/sbin : similar to /bin. but not intended for normal users. run by Linux.</li>
  <li>/proc : a virtual file system that exits in the kernels imagination, which is memory. not on a disk.
    <ul>
      <li>a directory with info about process number</li>
      <li>each process has a directory below /proc</li>
    </ul>
  </li>
  <li>/usr : contain all commands, libraries, man pages, games and static files for normal operations</li>
  <li>/boot : files used bu the bootstrap loader. kernel images are often kept here.</li>
  <li>/lib : shared libraries needed by the programs on the root file system</li>
  <li>/modules : loadable kernel modules, especially those needed to boot the system after disasters</li>
  <li>/dev : device files</li>
  <li>/etc : configuration files specific to the machine</li>
  <li>/skel : when a home directory is created, it is initialized with files from this directory</li>
  <li>/sysconfig : files that configure the linux system for devices</li>
  <li>/var : files that change for mail, news , printers log files, man pages, temp files</li>
  <li>/mnt : mount points for temporary mounts by the system administrator</li>
  <li>/tmp : temporary files. programs running after bootup should use /var/tmp</li>
</ul>

<h2 id="linuxarch">linux/arch</h2>
<ul>
  <li>subdirectories for each current port</li>
  <li>each contains <strong>kernel, lib, mm, boot</strong> and other directories whose contents override code stubs in architecture independent code</li>
</ul>

<h2 id="linuxdrivers">linux/drivers</h2>
<ul>
  <li>largest amount of code in the kernel tree</li>
  <li>device, bus, platform and general directories</li>
</ul>

<h2 id="linuxfs">linux/fs</h2>
<ul>
  <li>contains virtual file system framework (VFS) and subdirectories for actual file systems</li>
</ul>

<h2 id="linuxinclude">linux/include</h2>
<ul>
  <li>include/asm-* : architecture-dependent include subdirectories</li>
  <li>include/linux :
    <ul>
      <li>header info needed both by the kernel and user apps</li>
      <li>usually linked to /usr/include/linux</li>
      <li>kernel-only portions guarded by
        <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  #ifdef__KERNEL__
  /* kernel stuff */
  #endif
</code></pre></div>        </div>
        <h2 id="linuxinit">linux/init</h2>
      </li>
    </ul>
  </li>
  <li>version.c : contains the version banner that prints at boot</li>
  <li>main.c : architecture-independent boot code (start_kernel is the main entry point)</li>
</ul>

<h2 id="linuxkernel">linux/kernel</h2>
<ul>
  <li>the core kernel code</li>
  <li>sched.c : the main kernel file (scheduler, wait queues, timers, alarms, task queues)</li>
  <li>process control : fork.c, exec.c, signal.c, exit.c etc…</li>
  <li>kernel module support : kmod.c, ksyms.c, module.c</li>
  <li>other operations : time.c, resource.c, dma.c, printk.c, info.c, sys.c …</li>
</ul>

<h2 id="linuxlib">linux/lib</h2>
<ul>
  <li>kernel code cannot call standard C library routines</li>
</ul>

<h2 id="linuxmm">linux/mm</h2>
<ul>
  <li>paging and swapping</li>
  <li>allocation and deallocation</li>
  <li>memory mapping</li>
</ul>

<h2 id="linuxscripts">linux/scripts</h2>
<p>scripts for:</p>
<ul>
  <li>menu-based kernel configuration</li>
  <li>kernel patching</li>
  <li>generating kernel documentation</li>
</ul>

<h2 id="summary">Summary</h2>
<ul>
  <li>Linux is a modular, UNIX-like monolithic kernel</li>
  <li>kernel is the heart of the OS that executes with special hardware permission (kernel mode)</li>
  <li>“core kernel” provides framework, data structures, support for drivers, modules, subsystems</li>
  <li>architecture dependent source subtrees live in /arch</li>
</ul>

<h3 id="booting">Booting</h3>

<h2 id="how-computer-startup">How computer startup?</h2>
<ul>
  <li><strong>booting</strong> is a bootstrapping process that starts operating systems when the user turns on a computer system</li>
  <li>a <strong>boot sequence</strong> is the set of operations the computer performs when it is switched on that load an operating system</li>
</ul>

<h2 id="booting-sequence">Booting sequence</h2>
<ul>
  <li>Turn on</li>
  <li>CPU jump to address of BIOS (0xFFFF0)</li>
  <li>BIOS runs POST (Power-On Self Test)</li>
  <li>Find bootable devices</li>
  <li>Load and execute boot sector from MBR</li>
  <li>Load OS</li>
</ul>

<h2 id="bios-basic-inputoutput-system">BIOS (Basic Input/Output System)</h2>
<ul>
  <li>BIOS refers to the software code run by a computer when first powered on</li>
  <li>the primary function is code program embedded on a chip and controls various devices that make up the computer</li>
</ul>

<h2 id="mbr-master-boot-record">MBR (Master Boot Record)</h2>
<p><img src="https://lantaoyu.github.io/files/linux-figures/MBR.JPG" alt="MBR" /></p>

<ul>
  <li>OS is booted from a hard disk, where MBR contains the primary boot loader</li>
  <li>The MBR is a 512-byte sector, located in the first sector in the disk (sector 1 of cylinder 0, head 0)</li>
  <li>After the MBR is loaded into RAM, the BIOS yields control to it</li>
  <li>The first 446 bytes are the primary boot loader, which contains both executable code and error message</li>
  <li>The next 64 bytes are the partition table, which contains a record for each of four partitions</li>
  <li>The MBR ends with two bytes that are defined as the magic number (0xAA55 or 0x55AA). 
The magic number serves as a validation check of the MBR.</li>
  <li>To see the contents of MBR, use:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  sudo dd if=/dev/sda of=mbr.bin bs=512 count=1
  od -xa mbr.bin
</code></pre></div>    </div>
  </li>
</ul>

<h2 id="boot-loader">Boot loader</h2>
<ul>
  <li>more aptly called the kernel loader. the task at this stage is to load the linux kernel</li>
  <li>optional, initial RAM disk</li>
  <li>GRUB and LILO are the most popular Linux boot loader
    <ul>
      <li>GRUB: GRand Unified Bootloader
        <ul>
          <li>an operating system independent bootloader</li>
          <li>a multiboot software packet from GNU</li>
          <li>flexible command line interface</li>
          <li>file system access</li>
          <li>support multiple executable format</li>
          <li>support diskless system</li>
          <li>download OS from network</li>
        </ul>
      </li>
      <li>LILO: LInux LOader
        <ul>
          <li>not dependent on a specific file system</li>
          <li>can boot from hard disk and floppy</li>
          <li>up to 16 different images</li>
          <li>must change LILO when kernel image file or config file is changed</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="kernel-image">Kernel Image</h2>
<ul>
  <li>The kernel is the central part in most OS beacause of its task, which is the management of the system’s resources and the communication between hardware and software components.</li>
  <li>kernel always store in memory until computer is turned off.</li>
  <li>kernel image is not an executable kernel, but a compressed kernel image</li>
  <li>zImage size is less than 512 KB</li>
  <li>bzImage is larger than 512 KB</li>
</ul>

<h2 id="task-of-kernel">Task of kernel</h2>
<ul>
  <li>process management</li>
  <li>memory management</li>
  <li>device management</li>
  <li>system call</li>
</ul>

<h2 id="init-process">Init process</h2>
<ul>
  <li>the first thing the kernel does is to execute init process</li>
  <li>init is the root/parent of all processes executing in linux, and is responsible for staring all other processes</li>
  <li>the first process that init starts is a script: /etc/rc.d/rc.sysinit</li>
  <li>based on the appropriate run-level, scripts are executed to start various processes to run the system and make it functional</li>
  <li>the init process id is “1”</li>
  <li>init is responsible for starting system processes defined in /etc/inittab file</li>
  <li>init typically will start multiple instances of “getty”, which waits for console logins which spawn one’s user shell process</li>
  <li><strong>upon shutdown, init control the sequence and processes for shutdown</strong></li>
</ul>

<h2 id="runlevels">Runlevels</h2>
<ul>
  <li>a runlevel is a software configuration of the system which allows only a selected group of processes to exist</li>
  <li>init can be in one of seven runlevels: 0-6</li>
</ul>

<h2 id="rcd-files">rc#.d files</h2>
<ul>
  <li>rc#.d files are the scripts for a given runlevel that run during boot and shutdown</li>
  <li>the scripts are found in /etc/rc.d/rc#.d, where the symbol # represents the run level</li>
</ul>

<h2 id="initd">init.d</h2>
<ul>
  <li>deamon is a background process</li>
  <li>init.d is a directory that admin can start/stop individual deamons by changing on it</li>
  <li>admin can issue the command and either the satrt, stop, status, restart or reload option</li>
  <li>e.g. to stop the web server
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  cd /etc/rc.d/init.d/
  httpd stop
</code></pre></div>    </div>
  </li>
</ul>

<h2 id="实模式下的系统初始化">实模式下的系统初始化</h2>
<ul>
  <li>setup.S连同内核映象由bootsect.S装入。setup.S从BIOS获取计算机系统的参数,放到内存参数区,仍在实模式下运行</li>
  <li>辅助程序setup为内核映象的执行做好准备,然后跳转到0x10000(小内核),0x100000(大内核)开始内核本身的执行,此后就是内核的初始化过程</li>
  <li>setup.S:
    <ul>
      <li>版本检查和参数设置</li>
      <li>为进入保护模式做准备</li>
    </ul>
  </li>
</ul>

<h2 id="保护模式下的系统初始化">保护模式下的系统初始化</h2>
<ul>
  <li>初始化寄存器和数据区</li>
  <li>核心代码解压缩：调用<code class="language-plaintext highlighter-rouge">mics.c</code> 中的 <code class="language-plaintext highlighter-rouge">decompress_kernel</code></li>
  <li>页表初始化</li>
  <li>初始化 idt, gdt, ldt</li>
  <li>启动核心
    <ul>
      <li>前面是对CPU进行初始化，并启动保护模式</li>
      <li>现在的任务是初始化内核的核心数据结构，主要涉及：
        <ul>
          <li>中断管理</li>
          <li>进程管理</li>
          <li>内存管理</li>
          <li>设备管理</li>
        </ul>
      </li>
      <li>进入保护模式后，系统从<code class="language-plaintext highlighter-rouge">start_kernel</code>开始执行，<code class="language-plaintext highlighter-rouge">start_kernel</code>函数变成0号进程，不再返回</li>
      <li><code class="language-plaintext highlighter-rouge">Start_kernel</code>显示版本信息,调用<code class="language-plaintext highlighter-rouge">setup_arch()</code>初始化核心的数据结构</li>
      <li>最后,调用<code class="language-plaintext highlighter-rouge">kernel_thread()</code>创建1号进程<code class="language-plaintext highlighter-rouge">init</code>进程</li>
      <li>父进程创建<code class="language-plaintext highlighter-rouge">init</code>子进程之后,返回执行<code class="language-plaintext highlighter-rouge">cpu_idle</code></li>
    </ul>
  </li>
</ul>

<h2 id="qa">Q&amp;A</h2>
<ol>
  <li>Q: 在i386中,内核可执行代码在内存中的首地址是否可随意选择?<br />
A: 从原理上讲是可以的,但实际上要考虑许多因素。例如微机内存的低端1MB的地址空间是不连续的。所以要把内核代码放在低端就要看是否能放的下。如果内核代码模块太大就不能将内核放在低端。</li>
  <li>Q: 主引导扇区位于硬盘的什么位置,如果一个硬盘的主引导扇区有故障此硬盘是否还可以使用?<br />
A: 主引导扇区位于硬盘的0面0道1扇区。一般来讲如果一个硬盘的主引导扇区有故障,此硬盘虽然可以使用,但不能作为引导盘使用了,因为它的主引导扇区不能读出内容。</li>
</ol>

<h2 id="proc-file-system-and-kernel-module-programming">/proc File System and Kernel Module Programming</h2>
<h2 id="what-is-a-kernel-module">What is a kernel module?</h2>
<ul>
  <li>(wiki) an object file that contains code to extend the running kernel</li>
  <li>(RedHat) modules are pieces of code that can be loaded and unloaded into the kernel upon demand
    <h2 id="advantages-and-disadvantages">advantages and disadvantages</h2>
  </li>
  <li>advantages:
    <ul>
      <li>allowing the dynamic insertion and removal of code from the kernel at run-time</li>
      <li>save memory cost</li>
    </ul>
  </li>
  <li>disadvantages: fragmentation penalty -&gt; decrease memory performance</li>
</ul>

<h2 id="current-kernel-modules">current kernel modules</h2>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cd /lib/modules/2.6.32-22-generic/
find . -name "*.ko"
</code></pre></div></div>
<h2 id="current-loaded-modules">current loaded modules</h2>
<p><code class="language-plaintext highlighter-rouge">lsmod</code> or <code class="language-plaintext highlighter-rouge">cat /proc/modules</code></p>

<h2 id="proc">/proc</h2>
<ul>
  <li>a pseudo file system</li>
  <li>real time, resides in the <strong>virtual memory</strong></li>
  <li>tracks the processes running on the machine and the state of the system</li>
  <li>a new /proc file system is created every time your linux machine reboots</li>
  <li>highly dynamic. the size of the proc directory is 0 and the last time of modification is the last bootup time</li>
  <li>/proc file system doesn’t exist on any particular media</li>
  <li>the contents of the /proc file system can be read by anyone who has the requisite permissions</li>
  <li>certain parts of the /proc file system can be read only by the owner of the process and of course root (some not even by root)</li>
  <li>the contents of the /proc are used by many utilities which grab the data from the particular /proc directory and display it. e.g. top, ps, lspci, dmesg etc</li>
</ul>

<h2 id="tweak-kernel-parameters">Tweak kernel parameters</h2>
<ul>
  <li>/proc/sys: making changes to this directory enables you to make real time changes to certain kernel parameters</li>
  <li>e.g. /proc/sys/net/ipv4/ip_forward, which has value of “0”, which can be seen using <code class="language-plaintext highlighter-rouge">cat</code>. This can be changed in real time by <code class="language-plaintext highlighter-rouge">echo 1 &gt; /proc/sys/net/ipv4/ip_forward</code>, thus allowing IP forwarding.</li>
</ul>

<h2 id="details-of-some-files-in-proc">Details of some files in /proc</h2>
<ul>
  <li><strong>buddyinfo</strong>: contains the number of free areas of each order for the kernel buddy system</li>
  <li><strong>cmdline</strong>: kernel command line</li>
  <li><strong>cpuinfo</strong>: human-readable information about the processors</li>
  <li><strong>devices</strong>: list of device drivers configured into the currently running kernel (block and character)</li>
  <li><strong>dma</strong>: shows which DMA channels are being used at the moment</li>
  <li><strong>execdomains</strong>: related to security</li>
  <li><strong>fb</strong>: frame buffer devices</li>
  <li><strong>filesystems</strong>: filesystems configured/supported into/by the kernel</li>
  <li><strong>interrupts</strong>: number of interrupts per IRQ on the x86 architecture</li>
  <li><strong>iomem</strong>:  shows the current map of the system’s memory for its various devices</li>
  <li><strong>ioports</strong>: provides a list of currently registered port regions used for input or output communication with a device</li>
  <li><strong>kcore</strong>:
    <ul>
      <li>this file represents the physical memory of the system and is stored in the core file format</li>
      <li>unlike most /proc files, kcore does display a size. This value is given in bytes and is equal to the size of physical memory (RAM) used plus 4 KB.</li>
      <li>its content are designed to be examined by a debugger, such as gdb, the GNU Debugger</li>
      <li>only root user has the rights to view this file</li>
    </ul>
  </li>
  <li><strong>kmsg</strong>: used to hold messages generated by the kernel, which are then picked up by other programs, such as <code class="language-plaintext highlighter-rouge">klogd</code></li>
  <li><strong>loadavg</strong>:
    <ul>
      <li>provides a look at load average</li>
      <li>the first three columns measure CPU utilization of the last 1, 5 and 10 minutes periods.</li>
      <li>the fourth column shows the number of currently running processes and the total number of processes</li>
      <li>the last column displays the last process ID used</li>
    </ul>
  </li>
  <li><strong>locks</strong>: displays the files currently locked by the kernel</li>
  <li><strong>mdstat</strong>: contains the current information for multiple-disk, RAID configurations</li>
  <li><strong>meminfo</strong>:
    <ul>
      <li>one of the most commonly used /proc files</li>
      <li>it reports plenty of valuable information about the current utilization of RAM on the system</li>
    </ul>
  </li>
  <li><strong>misc</strong>: this files lists miscellaneous drivers registered on the miscellaneous major device, which is number 10</li>
  <li><strong>modules</strong>: displays a list of all modules that have been loade by the system</li>
  <li><strong>mounts</strong>: provides a quick list of all mounts in use by the system</li>
  <li><strong>mtrr</strong>: refers to the current Memory Type Range Registers (MTRRs) in use with the system</li>
  <li><strong>partitions</strong>: detailed information on the various partitions currently available to the system</li>
  <li><strong>pci</strong>: full list of every PCI device on your system</li>
  <li><strong>slabinfo</strong>: information about the memory usage on the slab level</li>
  <li><strong>stat</strong>: keeps track of a variety of different statistics about the system since it was last restarted</li>
  <li><strong>swap</strong>: measure swap space and its uilization</li>
  <li><strong>uptime</strong>: contains information about how long the system has on since its last restart</li>
  <li><strong>version</strong>: tells the versions of the kinux kernel and gcc, as well as the version of red hat linux installed on the system</li>
</ul>

<h2 id="the-numerical-named-directories">The numerical named directories</h2>
<ul>
  <li>the processed that are running at the instant a snapshot of the /proc file system was taken</li>
  <li>the contents of all the directories are the same as these directories contain the carious parameters and status of the corresponding process</li>
  <li>you have full access only to the processes that you have started</li>
</ul>

<h2 id="a-typical-process-directory">A typical process directory</h2>
<ul>
  <li>cmdline: contains the whole command line used to invoke the process. the contents of this file are the command line arguments with all the parameters (without formatting/spaces)</li>
  <li>cwd: symbolic link to the current working directory</li>
  <li>environ: contains all the process-specific environment variables</li>
  <li>exe: symbolic link of the executable</li>
  <li>maps: parts of the process’ address space mapped to a file</li>
  <li>fd: this directory contains the list of file descriptors as opened by the particular process</li>
  <li>root: symbolic link pointing to the directory which is the root file system for the particular process</li>
  <li>status: information about the process</li>
</ul>

<h2 id="other-subdirectories-in-proc">Other subdirectories in /proc</h2>
<ul>
  <li>/proc/self: link to the currently running process</li>
  <li>/proc/bus:
    <ul>
      <li>contains information specific to the various buses available on the system</li>
      <li>for ISA, PCI and USB buses, current data on each is available in /proc/bus/&lt;bus type directory&gt;</li>
      <li>individual bus directories, signified with numbers, contains binary files that refer to the various devices available on that bus</li>
    </ul>
  </li>
  <li>/proc/driver: specific drivers in use by kernel</li>
  <li>/proc/fs: specific file system, file handle, inode, dentry and quota information</li>
  <li>/proc/ide: information abput IDE devices</li>
  <li>/proc/irq: used to set IRQ to CPU affinity</li>
  <li>/proc/net: networking parameters and statistics
    <ul>
      <li>arp: kernel’s ARP table. useful for connecting hardware address to an IP address on a system</li>
      <li>dev: lists the network devices along with transmit and receive statistics</li>
      <li>route: displays the kernel’s routing table</li>
    </ul>
  </li>
  <li>/proc/scsi: like /proc/ide, it gives info about scsi devices</li>
  <li>/proc/sys:
    <ul>
      <li>allows you to make configuration changes to a running kernel, by <code class="language-plaintext highlighter-rouge">echo</code> command</li>
      <li>any configuration changes made will disappear when the system is restarted</li>
    </ul>
  </li>
</ul>

<h2 id="procsys-subdirectories">/proc/sys subdirectories</h2>
<ul>
  <li>/proc/sys/dev: provides parameters for particular devices on the system. e.g. <code class="language-plaintext highlighter-rouge">cdrom/info</code>: many important CD-ROM parameters</li>
  <li>/proc/sys/kernel:
    <ul>
      <li>acct: controls the suspension of process accounting based on the percentage of free space available on the filesystem containing the log</li>
      <li>ctrl-alt-del: controls whether [Ctrl]-[Alt]-[Delete] will gracefully restart the computer using init (value 0) or force an immediate reboot without syncing the dirty buffers to disk (value 1).</li>
      <li>domainname: allows you to configure the system’s domain name, such as domain.com.</li>
      <li>hostname: allows you to configure the system’s host name, such as host.domain.com</li>
      <li>threads-max: sets the maximum number of threads to be used in the kernel, with a default value of 4096</li>
      <li>panic: defines the number of seconds the kernel will postpone rebooting the system when a kernel panic is experienced. By default, the value is set to 0, which disables automatic rebooting after a panic.</li>
    </ul>
  </li>
  <li>/proc/sys/vm: facilitates the configuration of the Linux kernel’s virtual memory subsystem</li>
</ul>

<h2 id="advantages-and-disadvantages-of-the-proc-file-system">Advantages and disadvantages of the /proc file system</h2>
<ul>
  <li>advantages:
    <ul>
      <li>coherent, intuitive interface to the kernel</li>
      <li>great for tweaking and collecting status info</li>
      <li>easy to use and programming</li>
    </ul>
  </li>
  <li>disadvantages:
    <ul>
      <li>certain amount of overhead, must use fs calls, alleviated somewhat by sysctl() interface</li>
      <li>user can possibly cause system instability</li>
    </ul>
  </li>
</ul>

<h2 id="proc-file-system-entries">/proc file system entries</h2>
<ul>
  <li>to use any of the procfs functions, you have to include the correct header file <code class="language-plaintext highlighter-rouge">#include &lt;linux/proc_fs.h&gt;</code></li>
  <li><code class="language-plaintext highlighter-rouge">struct proc_dir_entry* create_proc_entry(const char* name, mode_t mode, struct proc_dir_entry* parent);</code>
    <ul>
      <li>this function creates a regular file with the name <code class="language-plaintext highlighter-rouge">name</code>, the mode <code class="language-plaintext highlighter-rouge">mode</code> in the directory <code class="language-plaintext highlighter-rouge">parent</code></li>
      <li>to create a file in the root of the procfs, use <code class="language-plaintext highlighter-rouge">NULL</code> as <code class="language-plaintext highlighter-rouge">parent</code> parameter</li>
      <li>when successful, the function will return a pointer to the freshly created <code class="language-plaintext highlighter-rouge">struct proc_dir_entry</code></li>
      <li>e.g. <code class="language-plaintext highlighter-rouge">foo_file = create_proc_entry("foo", 0644, example_dir);</code></li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">struct proc_dir_entry* proc_mkdir(const char* name, struct proc_dir_entry* parent);</code>
    <ul>
      <li>create a directory <code class="language-plaintext highlighter-rouge">name</code> in the procfs directory <code class="language-plaintext highlighter-rouge">parent</code></li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">struct proc_dir_entry* proc_symlink(const char* name, struct proc_dir_entry* parent, const char* dest);</code>
    <ul>
      <li>this creates a symlink in the procfs directory <code class="language-plaintext highlighter-rouge">parent</code> that points from <code class="language-plaintext highlighter-rouge">name</code> to <code class="language-plaintext highlighter-rouge">dest</code>. this translates in userland to ln -s dest name</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">void remove_proc_entry(const char* name, struct proc_dir_entry* parent);</code>
    <ul>
      <li>removes the entry <code class="language-plaintext highlighter-rouge">name</code> in the directory <code class="language-plaintext highlighter-rouge">parent</code> from the procfs.</li>
      <li>be sure to free the data entry from the struct <code class="language-plaintext highlighter-rouge">proc_dir_entry</code> before the function is called</li>
    </ul>
  </li>
</ul>

<h2 id="tips">Tips</h2>
<ul>
  <li>modules can only use APIs exported by kernel and other modules
    <ul>
      <li>no libcs</li>
      <li>kernel exports some common APIs</li>
    </ul>
  </li>
  <li>modules are part of kernel
    <ul>
      <li>modules can control the whole system</li>
      <li>as a result, can damage the whole system</li>
    </ul>
  </li>
  <li>modules basically can’t be written with C++</li>
  <li>determine which part should be in kernel</li>
</ul>

<h1 id="process-management">Process Management</h1>

<h2 id="processes-lightweight-processes-and-threads">Processes, Lightweight Processes and Threads</h2>
<ul>
  <li>Process: an instance of a program in execution</li>
  <li>(User) Thread: an execution flow of the process
    <ul>
      <li>Pthread (POSIX thread) library</li>
    </ul>
  </li>
  <li>Lightweight process (LWP): used to offer better support for multithreaded applications
    <ul>
      <li>LWP may share resources: address space, open files…</li>
      <li>To associate a lightweight process with each thread</li>
    </ul>
  </li>
</ul>

<h2 id="process-descriptor">Process descriptor</h2>
<p><code class="language-plaintext highlighter-rouge">task_struct</code> data structure:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">state</code>: process state</li>
  <li><code class="language-plaintext highlighter-rouge">thread_info</code>: low-level information for the process</li>
  <li><code class="language-plaintext highlighter-rouge">mm</code>: pointers to memory area descriptors</li>
  <li><code class="language-plaintext highlighter-rouge">tty</code>: tty associated with the process</li>
  <li><code class="language-plaintext highlighter-rouge">fs</code>: current directory</li>
  <li><code class="language-plaintext highlighter-rouge">files</code>: pointers to file descriptors</li>
  <li><code class="language-plaintext highlighter-rouge">signal</code>: signals received</li>
</ul>

<h2 id="process-state">Process state</h2>
<ul>
  <li>TASK_RUNNING: 该状态表示进程处于可运行状态，也就是说要么正在CPU中运行，要么在runqueue队列中等待运行</li>
  <li>TASK_INTERRUPTABLE: 该状态表示进程处于可中断的睡眠状态。该进程正处在睡眠，但是可以被任何信号唤醒。当信号将该进程唤醒后，进程会去对信号做出响应。</li>
  <li>TASK_UNINTERRUPTABLE: 该状态表示进程处于不可中断的睡眠状态。该进程正处于睡眠，专心等待某一个事件（一般是IO事件），并且不希望被其他信号唤醒。</li>
  <li>TASK_STOPPED</li>
  <li>TASK_TRACED</li>
  <li>EXIT_ZOMBIE: 该状态是该进程变为僵尸进程，即其父进程没有对该进程的结束信号进行处理</li>
  <li>EXIT_DEAD</li>
</ul>

<h2 id="identifying-a-process">Identifying a process</h2>
<ul>
  <li>process descriptor pointers: 32 bits</li>
  <li>process ID (PID): 16 bits (~32767 for compatibility)
    <ul>
      <li>linux associates different PID with each process or LWP</li>
      <li>programmers expect threads in the same group to have a common PID</li>
      <li>thread group: a collection of LWPs
        <ul>
          <li>the PID of the first LWP in the group</li>
          <li><code class="language-plaintext highlighter-rouge">tgid</code> field in process descriptor: using <code class="language-plaintext highlighter-rouge">getpid()</code> system call</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="the-process-list">The process list</h2>
<ul>
  <li><code class="language-plaintext highlighter-rouge">tasks</code> field in <code class="language-plaintext highlighter-rouge">task_struct</code> structure
    <ul>
      <li>type <code class="language-plaintext highlighter-rouge">list_head</code></li>
      <li><code class="language-plaintext highlighter-rouge">prev</code>, <code class="language-plaintext highlighter-rouge">next</code> fields point to the previous and the next <code class="language-plaintext highlighter-rouge">task_struct</code></li>
    </ul>
  </li>
  <li>process 0 (swapper): <code class="language-plaintext highlighter-rouge">init_task</code></li>
</ul>

<h2 id="parenthood-relationships-among-processes">Parenthood relationships among processes</h2>
<ul>
  <li>process 0 and 1: created by the kernel
    <ul>
      <li>process 1 <code class="language-plaintext highlighter-rouge">init</code>: the ancestor of all processes</li>
    </ul>
  </li>
  <li>fields in process descriptor for parenthood
    <ul>
      <li>real_parent</li>
      <li>parent</li>
      <li>children</li>
      <li>sibling</li>
    </ul>
  </li>
</ul>

<h2 id="pidhash-table-and-chained-lists">Pidhash table and chained lists</h2>
<ul>
  <li>to support the search for the process descriptor of a PID, since sequential search in the process list is inefficient</li>
  <li>the <code class="language-plaintext highlighter-rouge">pid_hash</code> array contains four hash tables and correspnding field in the process descriptor
    <ul>
      <li><code class="language-plaintext highlighter-rouge">pid</code>: PIDTYPE_PID</li>
      <li><code class="language-plaintext highlighter-rouge">tgid</code>: PIDTYPE_TGID (thread group leader)</li>
      <li><code class="language-plaintext highlighter-rouge">pgrp</code>: PIDTYPE_PGID (group leader)</li>
      <li><code class="language-plaintext highlighter-rouge">session</code>: PIDTYPE_SID (session leader)</li>
    </ul>
  </li>
  <li>chaining is used to handle PID collisions</li>
  <li>the size of each pidhash table is dependent on the available memory</li>
</ul>

<h2 id="pid">PID</h2>
<p><code class="language-plaintext highlighter-rouge">pids</code> field of the process descriptor: the pid data structure</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">nr</code>: PID number</li>
  <li><code class="language-plaintext highlighter-rouge">pid_chain</code>: links to the previous and the next elements in the hash chain list</li>
  <li><code class="language-plaintext highlighter-rouge">pid_list</code>: head of the per-PID list (in thread group)</li>
</ul>

<h2 id="how-processes-are-organized">How processes are organized</h2>
<ul>
  <li>processes in TASK_STOPPED, EXIT_ZOMBIE, EXIT_DEAD: not linked in lists</li>
  <li>processes in TASK_INTERRUPTABLE, TASK_UNINTERRUPTABLE: waiting queues</li>
  <li>two kinds of sleeping processes:
    <ul>
      <li>exclusive process</li>
      <li>nonexclusive process: always woken up by the kernel when the event occurs</li>
    </ul>
  </li>
</ul>

<h2 id="process-switch-task-switch-context-switch">Process switch, task switch, context switch</h2>
<ul>
  <li>hardware context switch: a far jmp (in older Linux)</li>
  <li>software context switch: a sequence of mov instructions
    <ul>
      <li>allows better control over the validity of data being loaded</li>
      <li>the amount of time required is about the same</li>
    </ul>
  </li>
</ul>

<h2 id="performing-the-process-switch">Performing the process switch</h2>
<ul>
  <li>switch the page global directory</li>
  <li>switch the kernel mode stack and the hardware context</li>
</ul>

<h2 id="task-state-segment">Task State Segment</h2>
<p><strong>TSS</strong>: a specific segment type in x86 architecture to store <strong>hardware contexts</strong></p>

<h2 id="creating-processes">Creating processes</h2>
<ul>
  <li>in traditional UNIX, resources owned by parent process are duplicated
    <ul>
      <li>very slow and inefficient</li>
      <li>mechanisms to solve this problem
        <ul>
          <li>Copy on Write: parent and child read the same physical page</li>
          <li>Ligitweight process (LWP): parent and child share per-process kernel data structures</li>
          <li><code class="language-plaintext highlighter-rouge">vfork()</code> system call: parent and child share the memory address space</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="clone-fork-and-vfork-system-calls"><code class="language-plaintext highlighter-rouge">clone()</code>, <code class="language-plaintext highlighter-rouge">fork()</code> and <code class="language-plaintext highlighter-rouge">vfork()</code> system calls</h2>
<ul>
  <li><code class="language-plaintext highlighter-rouge">clone(fn, arg, flags, child_stack, tls, ptid, ctid)</code>: creating lightweight process
    <ul>
      <li>a wrapper function in C library</li>
      <li>Uses <code class="language-plaintext highlighter-rouge">clone()</code> system call</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">fork()</code> and <code class="language-plaintext highlighter-rouge">vfork()</code> system calls: implemented by <code class="language-plaintext highlighter-rouge">clone</code> with different parameters</li>
  <li>each invokes <code class="language-plaintext highlighter-rouge">do_fork()</code> function</li>
</ul>

<h2 id="kernel-threads">Kernel threads</h2>
<ul>
  <li>kernel threads run only in kernel mode</li>
  <li>they use only linear addresses greater than PAGE_OFFSET</li>
  <li><code class="language-plaintext highlighter-rouge">kernel_thread()</code>: to create a kernel thread</li>
  <li>example kernel threads:
    <ul>
      <li>process 0 (swapper process), the ancestor of all processes</li>
      <li>process 1 (init process)</li>
      <li>others: keventd, kapm…</li>
    </ul>
  </li>
</ul>

<h2 id="destrying-processes">Destrying processes</h2>
<ul>
  <li><code class="language-plaintext highlighter-rouge">exit()</code> library function
    <ul>
      <li>two system calls in Linux 2.6
        <ul>
          <li><code class="language-plaintext highlighter-rouge">_exit()</code> system call: handled by <code class="language-plaintext highlighter-rouge">do_exit()</code> function</li>
          <li><code class="language-plaintext highlighter-rouge">exit_group()</code> system call: handled by <code class="language-plaintext highlighter-rouge">do_group_exit()</code> function</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>process removal: releasing the process descriptor of a zombie process by <code class="language-plaintext highlighter-rouge">release_task()</code></li>
</ul>

<h2 id="scheduling-policy">Scheduling policy</h2>
<ul>
  <li>based on time-sharing:
    <ul>
      <li>time slice</li>
    </ul>
  </li>
  <li>based on priority ranking:
    <ul>
      <li>dynamic</li>
    </ul>
  </li>
  <li>classification of processes:
    <ul>
      <li>interactive processes: e.g. shells, text editors, GUI applications</li>
      <li>batch processes: e.g. compilers, database search engine, web server</li>
      <li>real-time processes: e.g. audio/video applications, data-collection from physical sensors, robit controllers</li>
    </ul>
  </li>
</ul>

<h2 id="process-preemption">Process preemption</h2>
<ul>
  <li>Linux (user) processes are preemptive
    <ul>
      <li>when a new process has higher priority than the current</li>
      <li>when its time quantum expires, <code class="language-plaintext highlighter-rouge">TIF_NEED_RESCHED</code> in thread_info will be set</li>
    </ul>
  </li>
  <li>a preempted process is not suspended since it remains in the <strong>TASK_RUNNING</strong> state</li>
  <li>Linux kernel before 2.6 is nonpreemptive, simpler</li>
</ul>

<h2 id="how-long-should-a-quantum-last">How long should a quantum last</h2>
<ul>
  <li>neither too long nor too short:
    <ul>
      <li>too short: overhead for process switch</li>
      <li>too long: process no longer appear to be executed concurrently</li>
    </ul>
  </li>
  <li>always a compromise: the rule of thumb, to choose a duration as long as possible, while keeping good system response</li>
</ul>

<h2 id="scheduling-algorithm">Scheduling algorithm</h2>
<ul>
  <li>earlier version of Linux: simple and straightforward
    <ul>
      <li>at every process switch, scan the runnable processes, compute the priorities and select the best one to run</li>
    </ul>
  </li>
  <li>much more complex in Linux 2.6
    <ul>
      <li>scales well with the number of processes and processors</li>
      <li>constant time scheduling</li>
    </ul>
  </li>
  <li>3 scheduling classes
    <ul>
      <li>SCHED_FIFO: first-in first-out real-time</li>
      <li>SCHED_RR: round-robin real-time</li>
      <li>SCHED_NORMAL: conventional time-shared processes</li>
    </ul>
  </li>
</ul>

<h2 id="scheduling-of-conventional-processes">Scheduling of conventional processes</h2>
<h2 id="static-priority">Static priority</h2>
<ul>
  <li>static priority
    <ul>
      <li>conventional processes: 100 - 139
        <ul>
          <li>can be changed by <code class="language-plaintext highlighter-rouge">nice()</code>, <code class="language-plaintext highlighter-rouge">setpriority()</code> system calls</li>
        </ul>
      </li>
      <li>base time quantum: the time-quantum assigned by the scheduler if it has exhausted its previous time quantum <br />
  <img src="https://lantaoyu.github.io/files/linux-figures/base_time_quantum.png" alt="base time quantum" /></li>
    </ul>
  </li>
</ul>

<h2 id="dynamic-priority-and-average-sleep-time">Dynamic priority and average sleep time</h2>
<ul>
  <li>dynamic priority: 100 - 139</li>
  <li><code class="language-plaintext highlighter-rouge">dynamic priority = max(100, min(static_priority - bonus + 5, 139))</code>
    <ul>
      <li>bonus: 0 - 10
        <ul>
          <li>&lt; 5: penalty</li>
          <li>&gt; 5: premium</li>
        </ul>
      </li>
      <li>dependent on the <strong>average sleep time</strong>: average number of nanoseconds that the process spent while sleeping</li>
      <li>the more average sleep time, the more bonus:</li>
    </ul>
  </li>
</ul>

<h2 id="determine-the-status-of-a-process">Determine the status of a process</h2>
<p>To determine whether a process is considered to be interactive or batch</p>
<ul>
  <li>interactive if: dynamic_priority &lt;= 3 * static_priority / 4 + 28</li>
  <li>i.e. <code class="language-plaintext highlighter-rouge">bonux - 5 &gt;= static_priority / 4 - 28</code>
    <ul>
      <li>interactive delta</li>
    </ul>
  </li>
</ul>

<h2 id="active-and-expired-processes">Active and expired processes</h2>
<ul>
  <li>active processes: runnable processes that have not exhausted their time quantum</li>
  <li>expired processes: runnable processes that have exhausted their time quantum</li>
  <li>periodically, the role of processes changes</li>
</ul>

<h2 id="scheduling-of-real-time-processes">Scheduling of real-time processes</h2>
<ul>
  <li>real-time priority: 1 - 99</li>
  <li>real-time processes are always considered active
    <ul>
      <li>can be changed by <code class="language-plaintext highlighter-rouge">sched_setparam()</code> and <code class="language-plaintext highlighter-rouge">sched_setscheduler()</code> system calls</li>
    </ul>
  </li>
  <li>a real-time process is replaced only when:
    <ul>
      <li>another process has higher real-time priority</li>
      <li>put to sleep by blocking operation</li>
      <li>stopped or killed</li>
      <li>voluntarily relinquishes the CPU by <code class="language-plaintext highlighter-rouge">sched_yield()</code> system call</li>
      <li>for round-robin real time (SCHED_RR), time quantum exhausted</li>
    </ul>
  </li>
</ul>

<h2 id="implementation-support-of-scheduling">Implementation Support of Scheduling</h2>

<h2 id="data-structures-used-by-the-scheduler">Data structures used by the scheduler</h2>
<ul>
  <li><code class="language-plaintext highlighter-rouge">runqueue</code> data structure for each CPU</li>
  <li>two sets of runnable processes in the <code class="language-plaintext highlighter-rouge">runqueue</code> structure</li>
  <li><code class="language-plaintext highlighter-rouge">prio_array_t</code> data structure
    <ul>
      <li>nr_active: # of process descriptors in the list</li>
      <li>bitmap: priority bitmap</li>
      <li>queue: the 140 list_heads</li>
    </ul>
  </li>
</ul>

<h2 id="functions-used-by-the-scheduler">Functions used by the scheduler</h2>
<ul>
  <li><code class="language-plaintext highlighter-rouge">scheduler_tick()</code>: keep the time_slice counter up-to-date</li>
  <li><code class="language-plaintext highlighter-rouge">try_to_wake_up()</code> awaken a sleeping process</li>
  <li><code class="language-plaintext highlighter-rouge">recalc_task_prio()</code>: updates the dynamic priority</li>
  <li><code class="language-plaintext highlighter-rouge">load_balance()</code>: keep the runqueue of multiprocess system balanced</li>
  <li><code class="language-plaintext highlighter-rouge">schedule()</code>: select a new process to run
    <ul>
      <li>Direct invocation:
        <ul>
          <li>when the process must be blocked to wait for resource</li>
          <li>when long iterative tasks are executed in device drivers</li>
        </ul>
      </li>
      <li>Lazy invocation: by setting the TIF_NEED_RESCHED flag
        <ul>
          <li>when current process has used up its quantum, by <code class="language-plaintext highlighter-rouge">scheduler_tick()</code></li>
          <li>when a process is woken up, by <code class="language-plaintext highlighter-rouge">try_to_wake_up()</code></li>
          <li>when a <code class="language-plaintext highlighter-rouge">sched_setscheduler()</code> system call is issued</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="runqueue-balancing-in-multiprocessor-systems">Runqueue balancing in multiprocessor systems</h2>
<ul>
  <li>3 types of multiprocessor systems
    <ul>
      <li>Classic multiprocessor architecture</li>
      <li>Hyper-threading</li>
      <li>NUMA</li>
    </ul>
  </li>
  <li>A CPU can execute only the runnable processes in the corresponding runqueue</li>
  <li>The kernel periodically checks if the workloads of the runqueues are balanced</li>
</ul>

<h2 id="scheduling-domains">Scheduling domains</h2>
<p>A set of CPUs whose workloads are kept balanced by the kernel</p>
<ul>
  <li>hierarchically organized</li>
  <li>partitioned into groups: a subset of CPUs</li>
</ul>

<h2 id="system-calls-related-to-scheduling">System calls related to scheduling</h2>
<ul>
  <li><code class="language-plaintext highlighter-rouge">nice()</code>: for backward compatability only
    <ul>
      <li>allow processes to change their base priority</li>
      <li>replaced by <code class="language-plaintext highlighter-rouge">setpriority()</code></li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">getpriority()</code> and <code class="language-plaintext highlighter-rouge">setpriority()</code>:
    <ul>
      <li>act on the base priorities of all processes in a given group</li>
      <li>which: PRIO_PROCESS, PRIO_PGRP, PRIO_USER</li>
      <li>who: the value of pid, pgrp, or uid field to be used for selecting the processes</li>
      <li>niceval: the new base priority value: -20 - +19</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">sched_getscheduler()</code>, <code class="language-plaintext highlighter-rouge">sched_setscheduler()</code>: queries/sets the scheduling policy</li>
  <li><code class="language-plaintext highlighter-rouge">sched_getparam()</code>, <code class="language-plaintext highlighter-rouge">sched_setparam()</code>: queries/sets the scheduling parameters</li>
  <li><code class="language-plaintext highlighter-rouge">sched_yield()</code>: to relinquish the CPU voluntarily without being suspended</li>
  <li><code class="language-plaintext highlighter-rouge">sched_get_priority_min()</code>, <code class="language-plaintext highlighter-rouge">sched_get_priority_max()</code>: to return the minimum/maximum real-time static priority</li>
  <li><code class="language-plaintext highlighter-rouge">sched_rr_get_interval()</code>: to write into user space the round-robin time quantum for real-time process</li>
</ul>

<h2 id="completely-fair-scheduler-cfs">Completely Fair Scheduler (CFS)</h2>
<ul>
  <li>Motivation of CFS: running task gets 100% usage of the CPU, all other tasks get 0% usage of the CPU</li>
  <li>New scheduling algorithm in linux kernel 2.6</li>
  <li>Design:
    <ul>
      <li>the same <strong>virtual runtime</strong> for each task</li>
      <li>increasing the priority for sleeping task</li>
    </ul>
  </li>
  <li>Implementation
    <ul>
      <li>stores the records about the planned tasks in a <strong>red-black tree</strong></li>
      <li>pick efficiently the process that has used the least amount of time (the leftmost node of the tree)</li>
      <li>the entry of the picked process is then removed form the tree, the spent execution time is updated and the entry is then returned to the tree where it normally takes some other location.</li>
    </ul>
  </li>
</ul>

<h1 id="kernel-synchronization">Kernel synchronization</h1>
<h2 id="kernel-control-paths">Kernel control paths</h2>
<ul>
  <li>Linux kernel: like a server that answers requests
    <ul>
      <li>parts of the kernel run in an interleaved way</li>
    </ul>
  </li>
  <li>Kernel control path: a sequence of instructions executed in kernel mode on behalf of current process
    <ul>
      <li>interrupts and exceptions</li>
      <li>lighter than a process (less context)</li>
    </ul>
  </li>
  <li>Three CPU states are considered:
    <ul>
      <li>User: running a process in user mode</li>
      <li>Excp: running an exception or a system call handler</li>
      <li>Intr: running an interrupt handler</li>
    </ul>
  </li>
</ul>

<h2 id="kernel-preemption">Kernel preemption</h2>
<ul>
  <li>Preemptive kernel: a process running in kernel mode can be replaced by another process while in the middle of a kernel function</li>
  <li>The  main motivation for making a kernel preemptive is to reduce the <strong>dispatch latency</strong> of the user mode process
    <ul>
      <li>dispatch latency: delay between the time they become runnable and the time they actually begin running</li>
    </ul>
  </li>
  <li>The kernel can be preempted only when it is excuting an exception handler (in particular a system call) and the kernel preemption has not been explicitly disabled</li>
</ul>

<h2 id="when-synchronization-is-necessary">When synchronization is necessary</h2>
<ul>
  <li>A <strong>race condition</strong> can occur when the outcome of a computation depends on how two or more interleaved kernel control paths are nested</li>
  <li>To identify and protect the <strong>critical regions</strong> in exception handlers, interrupt handlers, deferrable functions, and kernel threads
    <ul>
      <li>On single CPU, critical region can be implemented by disabling interrupts while accessing shared data</li>
      <li>If the same data is shared only by the service routines of system calls, critical region can be implemented by disabling kernel preemption while accessing shared data</li>
    </ul>
  </li>
  <li>Things are more complicated on multiprocessor systems
    <ul>
      <li>different synchronization techniques are necessary</li>
    </ul>
  </li>
</ul>

<h2 id="when-synchronization-is-not-necessary">When synchronization is not necessary</h2>
<ul>
  <li>The same interrupt cannot occur until the handler terminates</li>
  <li>Interrupt handlers and softirqs are nonpreemptable, non-blocking</li>
  <li>A kernel control path performing interrupt handling cannot be interrupted by a kernel control path executing a deferrable function or a system call service routine</li>
  <li>Softirqs cannot be interleaved</li>
</ul>

<h2 id="per-cpu-variables">Per-CPU variables</h2>
<ul>
  <li>The simplest and most efficient synchronization technique consists of declaring kernel variables as per-cpu variables
    <ul>
      <li>an array of data structures, one element per CPU in the system</li>
      <li>a CPU should not access the elements of the array corresponding to the other CPUs</li>
    </ul>
  </li>
  <li>While per-cpu variables provide protection against concurrent accesses from several CPUs, they do not provide protection against accesses from asynchronous functions (interrupt handles and deferrable functions)</li>
  <li>per-cpu variables are prone to race conditions caused by kernel preemption, both in uniprocessor and multiprocessor systems</li>
</ul>

<h2 id="memory-barriers">Memory Barriers</h2>
<ul>
  <li>when dealing with synchronization, instruction reordering must be avoided</li>
  <li>a memory barrier primitive ensures that the operations before the primitive are finished before the operations after the primitive
    <ul>
      <li>all instructions that operate on I/O ports</li>
      <li>all instructions prefixed by lock byte</li>
      <li>all instructions that write into control registers, system registers or debug registers</li>
      <li>a few special instructions, e.g. iret</li>
    </ul>
  </li>
</ul>

<h2 id="spin-locks">Spin locks</h2>
<ul>
  <li>Spin locks are a special kind of lock designed to work in a multiprocessor environment
    <ul>
      <li>busy waiting</li>
      <li>very convenient</li>
    </ul>
  </li>
</ul>

<h2 id="readwrite-spin-locks">Read/Write Spin Locks</h2>
<ul>
  <li>To increase the amount of concurrency in the kernel
    <ul>
      <li>multiple reads, one write</li>
    </ul>
  </li>
  <li>rwlock_t structure
    <ul>
      <li>lock field: 32 bit</li>
    </ul>
  </li>
</ul>

<h2 id="seqlock">Seqlock</h2>
<ul>
  <li>Introduced in Linux 2.6</li>
  <li>similar to read/write spin locks</li>
  <li>except that they give a much higher priority to writers</li>
  <li>a writer is allowed to proceed even when readers are active</li>
</ul>

<h2 id="read-copy-update">Read-Copy Update</h2>
<ul>
  <li>Read-Copy update (RCU): another synchronization technique designed to protect data structures that are mostly accessed for reading by several CPUs
    <ul>
      <li>RCU allows many readers and many writers to proceed concurrently</li>
      <li>RCU is <strong>lock free</strong></li>
    </ul>
  </li>
  <li>Key ideas
    <ul>
      <li>only data structures that are dynamically allocated and referenced via pointers can be protected by RCU</li>
      <li>No kernel control path can sleep inside a critical section protected by RCU</li>
    </ul>
  </li>
</ul>

<h2 id="semaphores">Semaphores</h2>
<ul>
  <li>two kinds of semaphores
    <ul>
      <li>kernel semaphores: by kernel control paths</li>
      <li>System V IPC semaphores: by user processes</li>
    </ul>
  </li>
  <li>Kernel semaphores
    <ul>
      <li>struct semaphore
        <ul>
          <li>count</li>
          <li>wait</li>
          <li>sleepers</li>
        </ul>
      </li>
      <li><code class="language-plaintext highlighter-rouge">up()</code>: to release a kernel semaphore (similar to signal)</li>
      <li><code class="language-plaintext highlighter-rouge">down()</code>: to acquire kernel semaphore (similar to wait)</li>
    </ul>
  </li>
</ul>

<h2 id="readwrite-semaphores">Read/Write semaphores</h2>
<ul>
  <li>similar to read/write spin locks
    <ul>
      <li>except that waiting processes are suspended instead of spinning</li>
    </ul>
  </li>
  <li>struct rw_semaphore
    <ul>
      <li>count</li>
      <li>wait_list</li>
      <li>wait_lock</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">init_rwsem()</code></li>
  <li><code class="language-plaintext highlighter-rouge">down_read()</code>, <code class="language-plaintext highlighter-rouge">down_write</code>: acquire a read/write semaphore</li>
  <li><code class="language-plaintext highlighter-rouge">up_read()</code>,<code class="language-plaintext highlighter-rouge">up_write()</code>: release a read/write semaphore</li>
</ul>

<h2 id="completions">Completions</h2>
<ul>
  <li>to solve a subtle race condition in multiprocessor systems
    <ul>
      <li>similar to semaphores</li>
    </ul>
  </li>
  <li>struct completion
    <ul>
      <li>done</li>
      <li>wait</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">complete()</code>: corresponding to <code class="language-plaintext highlighter-rouge">up()</code></li>
  <li><code class="language-plaintext highlighter-rouge">wait_for_completion()</code>: corresponding to <code class="language-plaintext highlighter-rouge">down()</code></li>
</ul>

<h2 id="local-interrupt-disabling">Local interrupt disabling</h2>
<ul>
  <li>interrupts can be disabled on a CPU with <code class="language-plaintext highlighter-rouge">cli</code> instructions
    <ul>
      <li><code class="language-plaintext highlighter-rouge">local_irq_disable()</code> macro</li>
    </ul>
  </li>
  <li>interrupts can enabled by <code class="language-plaintext highlighter-rouge">sti</code> instructions
    <ul>
      <li><code class="language-plaintext highlighter-rouge">local_irq_enable()</code> macro</li>
    </ul>
  </li>
</ul>

<h2 id="disablingenabling-deferrable-functions">Disabling/Enabling deferrable functions</h2>
<ul>
  <li><code class="language-plaintext highlighter-rouge">softirq</code></li>
  <li>the kernel sometimes need to disable deferrable functions without diabling interrupts
    <ul>
      <li><code class="language-plaintext highlighter-rouge">local_bh_disable()</code> macro</li>
      <li><code class="language-plaintext highlighter-rouge">local_bh_enable()</code> macro</li>
    </ul>
  </li>
</ul>

<h2 id="synchronizing-accesses-to-kernel-data-structures">Synchronizing accesses to kernel data structures</h2>
<ul>
  <li>rule of thumb for kernel developers:
    <ul>
      <li>always keep the concurrency level as high as possible in the system</li>
      <li>two factors:
        <ul>
          <li>the number of I/O devices that operate concurrently</li>
          <li>the number of CPUs that do productive work</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>a shared data structure consisting of a single integer value can be updated by declaring it as an <code class="language-plaintext highlighter-rouge">atomic_t</code> type and by using atomic operations</li>
  <li>inserting an element into a shared linked list is never atomic since it consists of at leasr pointer assignments</li>
</ul>

<h2 id="examples-of-race-condition">Examples of race condition</h2>
<ul>
  <li>when a program uses two or more semaphores, the potential for deadlock is present because two different paths could wait for each other</li>
  <li>Linux has few problems with deadlocks on semaphore requests since each path usually acquire just one semaphore</li>
  <li>in cases such as <code class="language-plaintext highlighter-rouge">rmdir()</code> and <code class="language-plaintext highlighter-rouge">rename()</code> system calls, two semaphores requests</li>
  <li>to avoid such deadlocks, semaphore requests are performed in address order</li>
  <li>semaphore request are performed in predefined address order</li>
</ul>

<h1 id="symmetric-multiprocessing-smp">Symmetric multiprocessing (SMP)</h1>
<h2 id="traditional-view">Traditional View</h2>
<ul>
  <li>Traditionally, the computer has been viewed as a sequential machine
    <ul>
      <li>a processor executes instructions one at a time in sequence</li>
      <li>each instruction is a sequence of operations</li>
    </ul>
  </li>
  <li>two popular approached to providing parallelism
    <ul>
      <li>symmetric multiprocesors</li>
      <li>clusters</li>
    </ul>
  </li>
</ul>

<h2 id="categories-of-computer-systems">Categories of computer systems</h2>
<ul>
  <li>single instruction single data (SISD) stream
    <ul>
      <li>single processor executes a single instruction stream to operate on data stored in a single memory</li>
    </ul>
  </li>
  <li>Single instruction Multiple data (SIMD) stream
    <ul>
      <li>each instruction is executed on a different set of data by the different processors</li>
    </ul>
  </li>
  <li>multiple instruction single data (MISD) stream
    <ul>
      <li>a sequence of data is transmitted to a set of processors, each execute a different instruction sequence</li>
    </ul>
  </li>
  <li>multiple instruction multiple data (MIMD)
    <ul>
      <li>a set of processors simultaneously execute different instruction sequences on different data sets</li>
    </ul>
  </li>
</ul>

<h2 id="symmetric-multiprocessing">Symmetric multiprocessing</h2>
<ul>
  <li>kernel can execute on any processor
    <ul>
      <li>allowing portions of the kernel to execute in parallel</li>
      <li>typically each processor does self-scheduling from the pool of available process or threads</li>
    </ul>
  </li>
</ul>

<h2 id="smp">SMP</h2>
<ul>
  <li><strong>Symmetric multiprocessing (SMP)</strong> involves a multiprocessor computer hardware and software where two or more identical processors connect to a single shared main memory, have full access to all I/O devices and are controlled by a single OS instance that treats all processors equally, reserving none for special purposes</li>
  <li>Most multiprocessor systems today use an SMP architecture. In the case of multi-core processors, the SMP architecture applies to the cores, treating them as seperate processors</li>
</ul>

<h2 id="linux-support-for-smp">Linux Support for SMP</h2>
<ul>
  <li>启动过程:BSP负责操作系统的启动,在启动的最后阶段,BSP通过IPI激活各个AP,在系统的正常运行过程中,BSP和AP基本上是无差别的</li>
  <li>进程调度:与单处理器系统的主要差别是执行进程切换后,被换下的进程有可能会换到其他CPU上继续运行。在计算优先权时,如果进程上次运行的CPU也是当前CPU,则会适当提高优先权,这样可以更有效地利用Cache</li>
  <li>中断系统:为了支持SMP,在硬件上需要APIC中断控制系统。Linux定义了各种IPI的中断向量以及传送IPI的函数</li>
</ul>

<h2 id="numa">NUMA</h2>
<ul>
  <li><strong>Non-uniform memory access (NUMA)</strong> is a computer memory design used in multiprocessing, where the memory access time depends on the memory location relative to the processor</li>
  <li>Under NUMA, a processor can access its own local memory faster than non-local memory (memory local to another processor or memeory shared between processors)</li>
  <li>Benefits: the benefits of NUMA are limited to particular workloads, notably on servers where the data are often associated strongly with certain tasks or users</li>
</ul>

<h2 id="smp-系统启动过程">SMP 系统启动过程</h2>
<ol>
  <li>BIOS初始化：屏蔽AP(Application Processor),建立系统配置表</li>
  <li>MBR里面的引导程序(LILO,GRUB等)将内核载入内存</li>
  <li>执行 <code class="language-plaintext highlighter-rouge">head.S</code>中的 <code class="language-plaintext highlighter-rouge">startup_32</code>函数，最后调用 <code class="language-plaintext highlighter-rouge">start_kernel</code></li>
  <li>执行 <code class="language-plaintext highlighter-rouge">start_kernel</code>，这个函数相当于应用程序里面的 <code class="language-plaintext highlighter-rouge">main</code> 函数</li>
  <li><code class="language-plaintext highlighter-rouge">start_kernel</code> 进行一系列的初始化工作，最后将执行:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">smp_init</code>:关键的一步，启动各AP</li>
      <li><code class="language-plaintext highlighter-rouge">rest_init</code>，调用 <code class="language-plaintext highlighter-rouge">init</code> 创建1号 <code class="language-plaintext highlighter-rouge">init</code> 进程，自身调用 <code class="language-plaintext highlighter-rouge">cpu_idle</code>成为0号进程</li>
    </ul>
  </li>
  <li>1号进程 <code class="language-plaintext highlighter-rouge">init</code> 完成剩下的工作</li>
</ol>

<h2 id="reschedule_idle-工作过程"><code class="language-plaintext highlighter-rouge">reschedule_idle</code> 工作过程</h2>
<ol>
  <li>先检查p进程上一次运行的cpu是否空闲，如果空闲，这是最好的cpu，直接返回。</li>
  <li>找一个合适的cpu，查看SMP中的每个CPU上运行的进程，与p进程相比的抢先权，把具有最高的抢先权值的进程记录在target_task中，该进程运行的cpu为最合适的CPU。</li>
  <li>如target_task为空，说明没有找到合适的cpu，直接返回。</li>
  <li>如果target_task不为空，则说明找到了合适的cpu，因此将target_task-&gt;need_resched置为1，如果运行target_task的cpu不是当前运行的cpu，则向运行target_task的cpu发送一个IPI中断，让它重新调度。</li>
</ol>

<h1 id="memory-management---addressing">Memory Management - Addressing</h1>
<h2 id="memory-addresses">Memory Addresses</h2>
<ul>
  <li>three kinds of addresses in 80x86 microprocessors
    <ul>
      <li>logical address: included in the machine language instructions</li>
      <li>linear address (virtual address): a single 32-bit unsigned integer that can be used to address up to 4GB</li>
      <li>physical address (32-bit unsigned integers): used to address memory cells in memory chips</li>
      <li>logical address =&gt; <strong>segmentation unit</strong> =&gt; linear address =&gt; <strong>paging unit</strong> =&gt; physical address</li>
    </ul>
  </li>
</ul>

<h2 id="virtual-file-system-vfs">Virtual File System (VFS)</h2>

<h2 id="role-of-vfs">Role of VFS</h2>
<ul>
  <li>a common interface to several kinds of file systems</li>
  <li>File systems supported by the VFS
    <ul>
      <li>Disk-based filesystems</li>
      <li>Network filesystems</li>
      <li>special filesystems (e.g. /proc)</li>
    </ul>
  </li>
</ul>

<h2 id="common-file-system-interface">Common file system interface</h2>
<ul>
  <li>enable system calls such as <code class="language-plaintext highlighter-rouge">open()</code>, <code class="language-plaintext highlighter-rouge">read()</code> and <code class="language-plaintext highlighter-rouge">write()</code> to work regardless of file system or storage media</li>
</ul>

<h2 id="terminology">Terminology</h2>
<ul>
  <li>file system: storage of data adhering to a specific structure</li>
  <li>file: ordered string of bytes</li>
  <li>directory: analogous to a folder
    <ul>
      <li>special type of file</li>
      <li>instead of normal data, it contains <strong>pointers</strong> to other files</li>
      <li>directories are hooked together to create the hierarchical name space</li>
    </ul>
  </li>
  <li>metadata: information describing a file</li>
</ul>

<h2 id="physical-file-representation">Physical file representation</h2>
<ul>
  <li>Inode:
    <ul>
      <li>unique index</li>
      <li>holds file attributes and data block locations pertaining to a file</li>
    </ul>
  </li>
  <li>Data blocks
    <ul>
      <li>contain file data</li>
      <li>may not be physically contiguous</li>
    </ul>
  </li>
  <li>File name:
    <ul>
      <li>human-readable identifier for each file</li>
    </ul>
  </li>
</ul>

<h2 id="the-common-file-model">The common file model</h2>
<ul>
  <li>defines common file model conceptual interfaces and data structures</li>
  <li>e.g. user space (<code class="language-plaintext highlighter-rouge">write()</code>) =&gt; VFS (<code class="language-plaintext highlighter-rouge">sys_write()</code>) =&gt; file system (<code class="language-plaintext highlighter-rouge">file system write methods</code>) =&gt; physical media</li>
  <li>object-oriented: data structures and associated operations
    <ul>
      <li>Superblock object: a mounted file system</li>
      <li>Inode object: information about a file, represents a specific file</li>
      <li>File object: interaction between an open file and a process</li>
      <li>Dentry object: directory entry, single component of a path name</li>
    </ul>
  </li>
</ul>

<h2 id="vfs-operations">VFS operations</h2>
<ul>
  <li>each object contains operations object with methods:
    <ul>
      <li>super_operations: invoked on a specific file system</li>
      <li>inode_operations: invoked on a specific inodes (which point to a file)</li>
      <li>dentry_operations: invoked on a specific directory entry</li>
      <li>file_operations: invoked on a file</li>
    </ul>
  </li>
  <li>lower file system can implement own version of methods to be called by VFS</li>
  <li>if an operation is not defined by a lower file system (NULL), VFS will often call a generic version of the method</li>
</ul>

<h2 id="vfs-data-structures">VFS Data Structures</h2>

<h2 id="superblock-object">Superblock object</h2>
<ul>
  <li>implemented by each file system</li>
  <li>used to store information describing that specific file system</li>
  <li>often physically written at the beginning of the partition (file system control block)</li>
  <li>found in <code class="language-plaintext highlighter-rouge">linux/fs.h</code></li>
</ul>

<h2 id="inode-object">Inode object</h2>
<ul>
  <li>represent all the information needed to manipulate a file or directory</li>
  <li>constructed in memory, regardless of how file system stores metadata information</li>
  <li>three doubly linked lists
    <ul>
      <li>List of valid unused inodes</li>
      <li>List of in-use inodes</li>
      <li>List of dirty inodes</li>
    </ul>
  </li>
</ul>

<h1 id="power-management---from-linux-kernel-to-android">Power Management - From Linux Kernel to Android</h1>

<h2 id="linux-power-management">Linux Power Management</h2>
<ul>
  <li>Two popular power management standards in Linux
    <ul>
      <li>APM (Advanced Power Management)
        <ul>
          <li>Power management happens in two ways:
            <ol>
              <li>function calls from APM driver to the BIOS requesting power state change</li>
              <li>automatically based on device activities</li>
            </ol>
          </li>
          <li>Power states in APM:
            <ol>
              <li>Full on</li>
              <li>APM enabled</li>
              <li>APM standby</li>
              <li>APM suspend</li>
              <li>Sleep/Hibernation</li>
              <li>Off</li>
            </ol>
          </li>
          <li>Weakness of APM:
            <ol>
              <li>each BIOS has its own policy, different computers have different activities</li>
              <li>unable to know why system is suspend</li>
              <li>BIOS does not know user activities</li>
              <li>does not know add-on devices (USB)</li>
            </ol>
          </li>
        </ul>
      </li>
      <li>ACPI (Advanced Configuration and Power Interface)
        <ul>
          <li>control divided between OS and BIOS, decisions managed through OS</li>
          <li>Enables sophisticated power policies for general-purpose computers with standard usage patterns and hardware</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="android-power-management">Android Power Management</h2>
<ul>
  <li>Built on top of Linux Power Management</li>
  <li>Designed for devices which have a “default-off” behaviors
    <ul>
      <li>the phone is not supposed to be on when we do not want to use it</li>
      <li>powered on only when requested to be run, off by default</li>
      <li>unlike PC, which has a “default-on” behavior</li>
    </ul>
  </li>
  <li>Apps and services must request CPU resource with
<strong>“wake locks”</strong> through the Android application
framework (<code class="language-plaintext highlighter-rouge">PowerManager</code> class) and native Linux libraries in order to keep
power on, otherwise Android will shut down the CPU</li>
  <li>Android PM uses <strong>wake locks</strong> and <strong>time out</strong>
mechanism to switch state of system power, so that
system power consumption decreases</li>
  <li>If there are no wake locks, CPU will be turned off</li>
  <li>If there are <strong>partial wake locks</strong>, screen and keyboard will be turned off</li>
</ul>

<h2 id="android-pm-state-machine">Android PM State Machine</h2>
<ul>
  <li>When an user application acquire <strong>full wake lock</strong>
or <strong>screen/keyboard touch activity</strong> event occur,
the machine will enter ‘AWAKE’ state</li>
  <li>If timeout happens or power key is pressed, the machine will enter
<strong>“notification”</strong> state:
    <ul>
      <li>if partial wake lock is acquired, the machine will remain
  “notification”</li>
      <li>if all partial wake locks are released, the machine will
  enter <strong>“sleep”</strong> state
  <img src="https://lantaoyu.github.io/files/linux-figures/pm.png" alt="" /></li>
    </ul>
  </li>
  <li>There is one main wake lock called ‘main’ in the kernel
to keep the kernel awake
    <ul>
      <li>It is the last wake lock to be released when system goes to suspend
        <h2 id="acquiring-wake-locks">Acquiring wake locks</h2>
        <p><img src="https://lantaoyu.github.io/files/linux-figures/wake_lock.png" alt="" /></p>
        <ol>
          <li>request sent to PowerManager to acquire a wake lock</li>
          <li>PowerManagementService (in the kernel) to take a wake lock</li>
          <li>Add wake lock to the list</li>
          <li>set the power state:</li>
        </ol>
      </li>
      <li>for a full wake lock, state should be set to “ON”
        <ol>
          <li>For taking Partial wake lock, if it is the first partial
wake lock, a kernel wake lock is taken. This will
protect all the partial wake locks. For subsequent
requests, kernel wake lock is not taken, but just
added to the list</li>
        </ol>
      </li>
    </ul>
  </li>
</ul>

<h2 id="system-sleep">System Sleep</h2>
<p><img src="https://lantaoyu.github.io/files/linux-figures/sleep.png" alt="" /></p>
<ul>
  <li>early_suspend:
    <ul>
      <li>Used by drivers that need to handle power mode settings
  to the device before kernel is suspended</li>
      <li>Used to turn off screen and non-wakeup source input
  devices</li>
      <li>E.g., consider a display driver
        <ul>
          <li>In early suspend, the screen can be turned off</li>
          <li>In the suspend, other things like closing the driver can be done</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>late_resume:
    <ul>
      <li>When system is resumed, resume is called first, followed by resume late</li>
    </ul>
  </li>
</ul>

<h2 id="battery-service">Battery Service</h2>
<ul>
  <li>The <strong>BatteryService</strong> monitors the battery status, level, temperature etc.</li>
  <li>A <strong>Battery Driver</strong> in the kernel interacts with the physical battery via ADC to read battery voltage and I2C</li>
  <li>Whenever BatteryService receives information
from the BatteryDriver, it will act accordingly
    <ul>
      <li>E.g. if battery level is low, it will ask system to shutdown</li>
    </ul>
  </li>
  <li>Battery Service will monitor the battery status based on received uevent from the kernel
    <ul>
      <li>uevent : An asynchronous communication channel for kernel</li>
    </ul>
  </li>
</ul>]]></content><author><name>Yuxia Zhang</name><email>yuxiazh@bit.edu.cn</email></author><summary type="html"><![CDATA[Introduction Features Preemptive multitasking Virtual memory Shared libraries Demand loading, dynamic kernel modules TCP/IP networking Symmetrical Multi-Processing support Open source]]></summary></entry><entry><title type="html">Multi-Agent Reinforcement Learning Paper Lists</title><link href="http://localhost:4000/posts/2017/06/marl-papers/" rel="alternate" type="text/html" title="Multi-Agent Reinforcement Learning Paper Lists" /><published>2017-06-05T00:00:00-07:00</published><updated>2017-06-05T00:00:00-07:00</updated><id>http://localhost:4000/posts/2017/06/marl-papers</id><content type="html" xml:base="http://localhost:4000/posts/2017/06/marl-papers/"><![CDATA[<p>Multi-Agent Reinforcement Learning (MARL) is a very interesting research area, which has strong connections with single-agent RL, multi-agent systems, game theory, evolutionary computation and optimization theory.</p>

<p>This is a collection of research and review papers of multi-agent reinforcement learning (MARL). The Papers are sorted by time. Any suggestions and pull requests are welcome.</p>

<p>The sharing principle of these references here is for research. If any authors do not want their paper to be listed here, please feel free to contact <a href="https://lantaoyu.github.io/">Lantao Yu</a> (Email: lantaoyu [AT] hotmail.com).</p>

<h2 id="tutorial-and-books">Tutorial and Books</h2>
<ul>
  <li><a href="http://www.ecmlpkdd2013.org/wp-content/uploads/2013/09/Multiagent-Reinforcement-Learning.pdf">Multiagent Reinforcement Learning</a> by Daan Bloembergen, Daniel Hennes, Michael Kaisers, Peter Vrancx. ECML, 2013.</li>
  <li><a href="http://www.masfoundations.org/download.html">Multiagent systems: Algorithmic, game-theoretic, and logical foundations</a> by Shoham Y, Leyton-Brown K. Cambridge University Press, 2008.</li>
</ul>

<h2 id="review-papers">Review Papers</h2>
<ul>
  <li><a href="https://project-archive.inf.ed.ac.uk/msc/20162091/msc_proj.pdf">Deep Reinforcement Learning Variants of Multi-Agent Learning Algorithms</a> by Castaneda A O. 2016.</li>
  <li><a href="https://jair.org/media/4818/live-4818-8818-jair.pdf">Evolutionary Dynamics of Multi-Agent Learning: A Survey</a> by Bloembergen, Daan, et al. JAIR, 2015.</li>
  <li><a href="https://www.researchgate.net/publication/269100101_Game_Theory_and_Multi-agent_Reinforcement_Learning">Game theory and multi-agent reinforcement learning</a> by Nowé A, Vrancx P, De Hauwere Y M. Reinforcement Learning. Springer Berlin Heidelberg, 2012.</li>
  <li><a href="http://www.dcsc.tudelft.nl/~bdeschutter/pub/rep/10_003.pdf">Multi-agent reinforcement learning: An overview</a> by Buşoniu L, Babuška R, De Schutter B. Innovations in multi-agent systems and applications-1. Springer Berlin Heidelberg, 2010</li>
  <li><a href="http://www.dcsc.tudelft.nl/~bdeschutter/pub/rep/07_019.pdf">A comprehensive survey of multi-agent reinforcement learning</a> by Busoniu L, Babuska R, De Schutter B. IEEE Transactions on Systems Man and Cybernetics Part C Applications and Reviews, 2008</li>
  <li><a href="http://robotics.stanford.edu/~shoham/www%20papers/LearningInMAS.pdf">If multi-agent learning is the answer, what is the question?</a> by Shoham Y, Powers R, Grenager T. Artificial Intelligence, 2007.</li>
  <li><a href="http://users.isr.ist.utl.pt/~mtjspaan/readingGroup/learningNeto05.pdf">From single-agent to multi-agent reinforcement learning: Foundational concepts and methods</a> by Neto G. Learning theory course, 2005.</li>
  <li><a href="https://pdfs.semanticscholar.org/bb9f/bee22eae2b47bbf304804a6ac07def1aecdb.pdf">Evolutionary game theory and multi-agent reinforcement learning</a> by Tuyls K, Nowé A. The Knowledge Engineering Review, 2005.</li>
  <li><a href="https://www.researchgate.net/publication/221622801_An_Overview_of_Cooperative_and_Competitive_Multiagent_Learning">An Overview of Cooperative and Competitive Multiagent Learning</a> by Pieter Jan ’t HoenKarl TuylsLiviu PanaitSean LukeJ. A. La Poutré. AAMAS’s workshop LAMAS, 2005.</li>
</ul>

<h2 id="research-papers">Research Papers</h2>

<h3 id="framework">Framework</h3>
<ul>
  <li><a href="https://arxiv.org/pdf/1706.02275.pdf">Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments</a> by Lowe R, Wu Y, Tamar A, et al. arXiv, 2017.</li>
  <li><a href="https://arxiv.org/pdf/1703.06182.pdf">Deep Decentralized Multi-task Multi-Agent RL under Partial Observability</a> by Omidshafiei S, Pazis J, Amato C, et al. arXiv, 2017.</li>
  <li><a href="https://arxiv.org/pdf/1703.10069.pdf">Multiagent Bidirectionally-Coordinated Nets for Learning to Play StarCraft Combat Games</a> by Peng P, Yuan Q, Wen Y, et al. arXiv, 2017.</li>
  <li><a href="https://arxiv.org/pdf/1703.02702.pdf">Robust Adversarial Reinforcement Learning</a> by Lerrel Pinto, James Davidson, Rahul Sukthankar, Abhinav Gupta. arXiv, 2017.</li>
  <li><a href="https://arxiv.org/pdf/1702.08887.pdf">Stabilising Experience Replay for Deep Multi-Agent Reinforcement Learning</a> by Foerster J, Nardelli N, Farquhar G, et al. arXiv, 2017.</li>
  <li><a href="https://arxiv.org/pdf/1508.05328.pdf">Multiagent reinforcement learning with sparse interactions by negotiation and knowledge transfer</a> by Zhou L, Yang P, Chen C, et al. IEEE transactions on cybernetics, 2016.</li>
  <li><a href="https://arxiv.org/pdf/1409.4561.pdf">Decentralised multi-agent reinforcement learning for dynamic and uncertain environments</a> by Marinescu A, Dusparic I, Taylor A, et al. arXiv, 2014.</li>
  <li><a href="http://irll.eecs.wsu.edu/wp-content/papercite-data/pdf/2014iat-holmesparker.pdf">CLEANing the reward: counterfactual actions to remove exploratory action noise in multiagent learning</a> by HolmesParker C, Taylor M E, Agogino A, et al. AAMAS, 2014.</li>
  <li><a href="http://www.fransoliehoek.net/docs/Amato13MSDM.pdf">Bayesian reinforcement learning for multiagent systems with state uncertainty</a> by Amato C, Oliehoek F A. MSDM Workshop, 2013.</li>
  <li><a href="http://www.weiss-gerhard.info/publications/AI_MAGAZINE_2012_TuylsWeiss.pdf">Multiagent learning: Basics, challenges, and prospects</a> by Tuyls, Karl, and Gerhard Weiss. AI Magazine, 2012.</li>
  <li><a href="http://icml2010.haifa.il.ibm.com/papers/191.pdf">Classes of multiagent q-learning dynamics with epsilon-greedy exploration</a> by Wunder M, Littman M L, Babes M. ICML, 2010.</li>
  <li><a href="http://www.machinelearning.org/proceedings/icml2007/papers/89.pdf">Conditional random fields for multi-agent reinforcement learning</a> by Zhang X, Aberdeen D, Vishwanathan S V N. ICML, 2007.</li>
  <li><a href="http://ama.imag.fr/~partalas/partalasmarl.pdf">Multi-agent reinforcement learning using strategies and voting</a> by Partalas, Ioannis, Ioannis Feneris, and Ioannis Vlahavas. ICTAI, 2007.</li>
  <li><a href="https://pdfs.semanticscholar.org/57fb/ae00e17c0d798559ebab0e8f4267e032f41d.pdf">A reinforcement learning scheme for a partially-observable multi-agent game</a> by Ishii S, Fujita H, Mitsutake M, et al. Machine Learning, 2005.</li>
  <li><a href="http://lib.tkk.fi/Diss/2004/isbn9512273594/article1.pdf">Asymmetric multiagent reinforcement learning</a> by Könönen V. Web Intelligence and Agent Systems, 2004.</li>
  <li><a href="http://dl.acm.org/citation.cfm?id=860686">Adaptive policy gradient in multiagent learning</a> by Banerjee B, Peng J. AAMAS, 2003.</li>
  <li><a href="https://papers.nips.cc/paper/2171-reinforcement-learning-to-play-an-optimal-nash-equilibrium-in-team-markov-games.pdf">Reinforcement learning to play an optimal Nash equilibrium in team Markov games</a> by Wang X, Sandholm T. NIPS, 2002.</li>
  <li><a href="http://www.sts.rpi.edu/~rsun/si-mal/article3.pdf">Value-function reinforcement learning in Markov game</a> by Littman M L. Cognitive Systems Research, 2001.</li>
  <li><a href="http://researchers.lille.inria.fr/~ghavamza/my_website/Publications_files/agents01.pdf">Hierarchical multi-agent reinforcement learning</a> by Makar, Rajbala, Sridhar Mahadevan, and Mohammad Ghavamzadeh. The fifth international conference on Autonomous agents, 2001.</li>
</ul>

<h3 id="joint-action-learning">Joint action learning</h3>
<ul>
  <li><a href="http://www.cs.cmu.edu/~conitzer/awesomeML06.pdf">AWESOME: A general multiagent learning algorithm that converges in self-play and learns a best response against stationary opponents</a> by Conitzer V, Sandholm T. Machine Learning, 2007.</li>
  <li><a href="https://papers.nips.cc/paper/2503-extending-q-learning-to-general-adaptive-multi-agent-systems.pdf">Extending Q-Learning to General Adaptive Multi-Agent Systems</a> by Tesauro, Gerald. NIPS, 2003.</li>
  <li><a href="http://www.lirmm.fr/~jq/Cours/3cycle/module/HuWellman98icml.pdf">Multiagent reinforcement learning: theoretical framework and an algorithm.</a> by Hu, Junling, and Michael P. Wellman. ICML, 1998.</li>
  <li><a href="http://www.aaai.org/Papers/AAAI/1998/AAAI98-106.pdf">The dynamics of reinforcement learning in cooperative multiagent systems</a> by Claus C, Boutilier C. AAAI, 1998.</li>
  <li><a href="https://www.cs.duke.edu/courses/spring07/cps296.3/littman94markov.pdf">Markov games as a framework for multi-agent reinforcement learning</a> by Littman, Michael L. ICML, 1994.</li>
</ul>

<h3 id="cooperation-and-competition">Cooperation and competition</h3>
<ul>
  <li><a href="https://arxiv.org/pdf/1702.03037.pdf">Multi-agent Reinforcement Learning in Sequential Social Dilemmas</a> by Leibo J Z, Zambaldi V, Lanctot M, et al. arXiv, 2017. [<a href="https://deepmind.com/blog/understanding-agent-cooperation/">Post</a>]</li>
  <li><a href="http://www.umiacs.umd.edu/~hal/docs/daume16opponent.pdf">Opponent Modeling in Deep Reinforcement Learning</a> by He H, Boyd-Graber J, Kwok K, et al. ICML, 2016.</li>
  <li><a href="https://arxiv.org/pdf/1511.08779.pdf">Multiagent cooperation and competition with deep reinforcement learning</a> by Tampuu A, Matiisen T, Kodelja D, et al. arXiv, 2015.</li>
  <li><a href="http://www.uow.edu.au/~fren/documents/EMR_2013.pdf">Emotional multiagent reinforcement learning in social dilemmas</a> by Yu C, Zhang M, Ren F. International Conference on Principles and Practice of Multi-Agent Systems, 2013.</li>
  <li><a href="http://www.jmlr.org/papers/volume9/bab08a/bab08a.pdf">Multi-agent reinforcement learning in common interest and fixed sum stochastic games: An experimental study</a> by Bab, Avraham, and Ronen I. Brafman. Journal of Machine Learning Research, 2008.</li>
  <li><a href="https://pdfs.semanticscholar.org/5120/d9f2c738ad223e9f8f14cb3fd5612239a35c.pdf">Combining policy search with planning in multi-agent cooperation</a> by Ma J, Cameron S. Robot Soccer World Cup, 2008.</li>
  <li><a href="http://www.jmlr.org/papers/volume7/kok06a/kok06a.pdf">Collaborative multiagent reinforcement learning by payoff propagation</a> by Kok J R, Vlassis N. JMLR, 2006.</li>
  <li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.107.335&amp;rep=rep1&amp;type=pdf">Learning to cooperate in multi-agent social dilemmas</a> by de Cote E M, Lazaric A, Restelli M. AAMAS, 2006.</li>
  <li><a href="http://www.machinelearning.org/proceedings/icml2005/papers/021_Learning_CrandallGoodrich.pdf">Learning to compete, compromise, and cooperate in repeated general-sum games</a> by Crandall J W, Goodrich M A. ICML, 2005.</li>
  <li><a href="http://www.machinelearning.org/proceedings/icml2004/papers/267.pdf">Sparse cooperative Q-learning</a> by Kok J R, Vlassis N. ICML, 2004.</li>
</ul>

<h3 id="coordination">Coordination</h3>
<ul>
  <li><a href="https://arxiv.org/pdf/1703.03121.pdf">Coordinated Multi-Agent Imitation Learning</a> by Le H M, Yue Y, Carr P. arXiv, 2017.</li>
  <li><a href="http://mipc.inf.ed.ac.uk/2014/papers/mipc2014_hao_etal.pdf">Reinforcement social learning of coordination in networked cooperative multiagent systems</a> by Hao J, Huang D, Cai Y, et al. AAAI Workshop, 2014.</li>
  <li><a href="http://www.aamas-conference.org/Proceedings/aamas2013/docs/p1101.pdf">Coordinating multi-agent reinforcement learning with limited communication</a> by Zhang, Chongjie, and Victor Lesser. AAMAS, 2013.</li>
  <li><a href="http://www.ifaamas.org/Proceedings/aamas2012/papers/1B_1.pdf">Coordination guided reinforcement learning</a> by Lau Q P, Lee M L, Hsu W. AAMAS, 2012.</li>
  <li><a href="https://www.cs.toronto.edu/~cebly/Papers/bayesMARL.pdf">Coordination in multiagent reinforcement learning: a Bayesian approach</a> by Chalkiadakis G, Boutilier C. AAMAS, 2003.</li>
  <li><a href="https://users.cs.duke.edu/~parr/icml02.pdf">Coordinated reinforcement learning</a> by Guestrin C, Lagoudakis M, Parr R. ICML, 2002.</li>
  <li><a href="http://www.aaai.org/Papers/AAAI/2002/AAAI02-050.pdf">Reinforcement learning of coordination in cooperative multi-agent systems</a> by Kapetanakis S, Kudenko D. AAAI/IAAI, 2002.</li>
</ul>

<h3 id="security">Security</h3>
<ul>
  <li><a href="http://www.fransoliehoek.net/docs/Klima16LICMAS.pdf">Markov Security Games: Learning in Spatial Security Problems</a> by Klima R, Tuyls K, Oliehoek F. The Learning, Inference and Control of Multi-Agent Systems at NIPS, 2016.</li>
  <li><a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7244682">Cooperative Capture by Multi-Agent using Reinforcement Learning, Application for Security Patrol Systems</a> by Yasuyuki S, Hirofumi O, Tadashi M, et al. Control Conference (ASCC), 2015</li>
  <li><a href="http://www4.ncsu.edu/~hdai/infocom-2015-XH.pdf">Improving learning and adaptation in security games by exploiting information asymmetry</a> by He X, Dai H, Ning P. INFOCOM, 2015.</li>
</ul>

<h3 id="self-play">Self-Play</h3>
<ul>
  <li><a href="https://arxiv.org/pdf/1603.01121.pdf">Deep reinforcement learning from self-play in imperfect-information games</a> by Heinrich, Johannes, and David Silver. arXiv, 2016.</li>
  <li><a href="http://jmlr.org/proceedings/papers/v37/heinrich15.pdf">Fictitious Self-Play in Extensive-Form Games</a> by Heinrich, Johannes, Marc Lanctot, and David Silver. ICML, 2015.</li>
</ul>

<h3 id="learning-to-communicate">Learning To Communicate</h3>
<ul>
  <li><a href="https://openreview.net/pdf?id=SkaxnKEYg">EMERGENCE OF LANGUAGE WITH MULTI-AGENT GAMES: LEARNING TO COMMUNICATE WITH SEQUENCES OF SYMBOLS</a> by Serhii Havrylov, Ivan Titov. ICLR Workshop, 2017.</li>
  <li><a href="https://arxiv.org/pdf/1703.06585.pdf">Learning Cooperative Visual Dialog Agents with Deep Reinforcement Learning</a> by Abhishek Das, Satwik Kottur, et al. arXiv, 2017.</li>
  <li><a href="https://arxiv.org/pdf/1703.04908.pdf">Emergence of Grounded Compositional Language in Multi-Agent Populations</a> by Igor Mordatch, Pieter Abbeel. arXiv, 2017. [<a href="https://openai.com/blog/learning-to-communicate/">Post</a>]</li>
  <li><a href="https://repositories.lib.utexas.edu/handle/2152/45681">Cooperation and communication in multiagent deep reinforcement learning</a> by Hausknecht M J. 2017.</li>
  <li><a href="https://openreview.net/pdf?id=Hk8N3Sclg">Multi-agent cooperation and the emergence of (natural) language</a> by Lazaridou A, Peysakhovich A, Baroni M. arXiv, 2016.</li>
  <li><a href="https://arxiv.org/pdf/1602.02672.pdf">Learning to communicate to solve riddles with deep distributed recurrent q-networks</a> by Foerster J N, Assael Y M, de Freitas N, et al. arXiv, 2016.</li>
  <li><a href="https://arxiv.org/pdf/1605.06676.pdf">Learning to communicate with deep multi-agent reinforcement learning</a> by Foerster J, Assael Y M, de Freitas N, et al. NIPS, 2016.</li>
  <li><a href="http://papers.nips.cc/paper/6398-learning-multiagent-communication-with-backpropagation.pdf">Learning multiagent communication with backpropagation</a> by Sukhbaatar S, Fergus R. NIPS, 2016.</li>
  <li><a href="http://people.csail.mit.edu/lpk/papers/dars08.pdf">Efficient distributed reinforcement learning through agreement</a> by Varshavskaya P, Kaelbling L P, Rus D. Distributed Autonomous Robotic Systems, 2009.</li>
</ul>

<h3 id="transfer-learning">Transfer Learning</h3>
<ul>
  <li><a href="https://www.ijcai.org/Proceedings/16/Papers/565.pdf">Transfer Learning for Multiagent Reinforcement Learning Systems</a> by da Silva, Felipe Leno, and Anna Helena Reali Costa. IJCAI, 2016.</li>
  <li><a href="https://web.cs.umass.edu/publication/docs/2015/UM-CS-2015-004.pdf">Accelerating multi-agent reinforcement learning with dynamic co-learning</a> by Garant D, da Silva B C, Lesser V, et al. Technical report, 2015</li>
  <li><a href="https://www.scss.tcd.ie/~tayloral/res/papers/Taylor_ParallelTransferLearning_ICML_2013.pdf">Transfer learning in multi-agent systems through parallel transfer</a> by Taylor, Adam, et al. ICML, 2013.</li>
  <li><a href="https://ewrl.files.wordpress.com/2011/08/ewrl2011_submission_19.pdf">Transfer learning in multi-agent reinforcement learning domains</a> by Boutsioukis, Georgios, Ioannis Partalas, and Ioannis Vlahavas. European Workshop on Reinforcement Learning, 2011.</li>
  <li><a href="https://ai.vub.ac.be/~ydehauwe/publications/ICAART2011_2.pdf">Transfer Learning for Multi-agent Coordination</a> by Vrancx, Peter, Yann-Michaël De Hauwere, and Ann Nowé. ICAART, 2011.</li>
</ul>

<h3 id="inverse-reinforcement-learning">Inverse Reinforcement Learning</h3>
<ul>
  <li><a href="http://papers.nips.cc/paper/6420-cooperative-inverse-reinforcement-learning.pdf">Cooperative inverse reinforcement learning</a> by Hadfield-Menell D, Russell S J, Abbeel P, et al. NIPS, 2016.</li>
  <li><a href="https://arxiv.org/pdf/1403.6822.pdf">Comparison of Multi-agent and Single-agent Inverse Learning on a Simulated Soccer Example</a> by Lin X, Beling P A, Cogill R. arXiv, 2014.</li>
  <li><a href="https://arxiv.org/pdf/1403.6508.pdf">Multi-agent inverse reinforcement learning for zero-sum games</a> by Lin X, Beling P A, Cogill R. arXiv, 2014.</li>
  <li><a href="http://aamas2014.lip6.fr/proceedings/aamas/p173.pdf">Multi-robot inverse reinforcement learning under occlusion with interactions</a> by Bogert K, Doshi P. AAMAS, 2014.</li>
  <li><a href="http://homes.soic.indiana.edu/natarasr/Papers/mairl.pdf">Multi-agent inverse reinforcement learning</a> by Natarajan S, Kunapuli G, Judah K, et al. ICMLA, 2010.</li>
</ul>

<h3 id="application">Application</h3>
<ul>
  <li><a href="https://arxiv.org/pdf/1702.05573.pdf">Collaborative Deep Reinforcement Learning for Joint Object Search</a> by Kong X, Xin B, Wang Y, et al. arXiv, 2017.</li>
  <li><a href="https://arxiv.org/pdf/1610.03295.pdf">Safe, Multi-Agent, Reinforcement Learning for Autonomous Driving</a> by Shalev-Shwartz S, Shammah S, Shashua A. arXiv, 2016.</li>
  <li><a href="https://www.researchgate.net/profile/Karl_Mason/publication/299416955_Applying_Multi-Agent_Reinforcement_Learning_to_Watershed_Management/links/56f545b908ae95e8b6d1d3ff.pdf">Applying multi-agent reinforcement learning to watershed management</a> by Mason, Karl, et al. Proceedings of the Adaptive and Learning Agents workshop at AAMAS, 2016.</li>
  <li><a href="http://www.aaai.org/ocs/index.php/AIIDE/AIIDE10/paper/viewFile/2112/2550">Crowd Simulation Via Multi-Agent Reinforcement Learning</a> by Torrey L. AAAI, 2010.</li>
  <li><a href="https://pdfs.semanticscholar.org/61bc/b98b7ae3df894f4f72aba3d145bd48ca2cd5.pdf">Traffic light control by multiagent reinforcement learning systems</a> by Bakker, Bram, et al. Interactive Collaborative Information Systems, 2010.</li>
  <li><a href="https://staff.science.uva.nl/s.a.whiteson/pubs/kuyerecml08.pdf">Multiagent reinforcement learning for urban traffic control using coordination graphs</a> by Kuyer, Lior, et al. oint European Conference on Machine Learning and Knowledge Discovery in Databases, 2008.</li>
  <li><a href="https://www.researchgate.net/publication/221465347_A_Multi-agent_Q-learning_Framework_for_Optimizing_Stock_Trading_Systems">A multi-agent Q-learning framework for optimizing stock trading systems</a> by Lee J W, Jangmin O. DEXA, 2002.</li>
  <li><a href="http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=422747CB9AF552CF1C4E455220E3F96F?doi=10.1.1.32.9887&amp;rep=rep1&amp;type=pdf">Multi-agent reinforcement learning for traffic light control</a> by Wiering, Marco. ICML. 2000.</li>
</ul>]]></content><author><name>Yuxia Zhang</name><email>yuxiazh@bit.edu.cn</email></author><summary type="html"><![CDATA[Multi-Agent Reinforcement Learning (MARL) is a very interesting research area, which has strong connections with single-agent RL, multi-agent systems, game theory, evolutionary computation and optimization theory.]]></summary></entry></feed>